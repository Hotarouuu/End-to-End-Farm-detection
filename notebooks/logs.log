2026-02-07 13:54:24,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-07 13:54:24,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-07 13:54:24,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-07 13:54:24,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-07 14:27:31,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-07 14:27:31,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-07 14:27:31,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-07 14:27:31,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-07 14:27:47,610:INFO:PyCaret ClassificationExperiment
2026-02-07 14:27:47,610:INFO:Logging name: clf-default-name
2026-02-07 14:27:47,611:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-02-07 14:27:47,611:INFO:version 3.3.2
2026-02-07 14:27:47,611:INFO:Initializing setup()
2026-02-07 14:27:47,611:INFO:self.USI: 05ee
2026-02-07 14:27:47,611:INFO:self._variable_keys: {'pipeline', 'data', 'fix_imbalance', 'html_param', 'USI', 'y_train', 'target_param', 'X', 'idx', 'fold_groups_param', 'log_plots_param', 'seed', 'exp_name_log', 'y_test', 'is_multiclass', 'memory', 'X_test', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'logging_param', 'fold_shuffle_param', 'fold_generator', 'X_train', 'gpu_param', 'y', '_ml_usecase', '_available_plots'}
2026-02-07 14:27:47,612:INFO:Checking environment
2026-02-07 14:27:47,612:INFO:python_version: 3.11.14
2026-02-07 14:27:47,612:INFO:python_build: ('main', 'Nov 19 2025 22:47:14')
2026-02-07 14:27:47,612:INFO:machine: x86_64
2026-02-07 14:27:47,612:INFO:platform: Linux-6.14.0-37-generic-x86_64-with-glibc2.39
2026-02-07 14:27:47,613:INFO:Memory: svmem(total=8011517952, available=1732091904, percent=78.4, used=6279426048, free=374341632, active=2949287936, inactive=3422744576, buffers=60833792, cached=2350735360, shared=928104448, slab=532312064)
2026-02-07 14:27:47,615:INFO:Physical Core: 10
2026-02-07 14:27:47,615:INFO:Logical Core: 12
2026-02-07 14:27:47,615:INFO:Checking libraries
2026-02-07 14:27:47,615:INFO:System:
2026-02-07 14:27:47,615:INFO:    python: 3.11.14 (main, Nov 19 2025, 22:47:14) [Clang 21.1.4 ]
2026-02-07 14:27:47,616:INFO:executable: /home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/bin/python
2026-02-07 14:27:47,616:INFO:   machine: Linux-6.14.0-37-generic-x86_64-with-glibc2.39
2026-02-07 14:27:47,616:INFO:PyCaret required dependencies:
2026-02-07 14:27:47,619:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:47,815:INFO:                 pip: Not installed
2026-02-07 14:27:47,815:INFO:          setuptools: 81.0.0
2026-02-07 14:27:47,815:INFO:             pycaret: 3.3.2
2026-02-07 14:27:47,815:INFO:             IPython: 9.10.0
2026-02-07 14:27:47,815:INFO:          ipywidgets: 8.1.8
2026-02-07 14:27:47,815:INFO:                tqdm: 4.67.3
2026-02-07 14:27:47,815:INFO:               numpy: 1.26.4
2026-02-07 14:27:47,815:INFO:              pandas: 2.1.4
2026-02-07 14:27:47,815:INFO:              jinja2: 3.1.6
2026-02-07 14:27:47,815:INFO:               scipy: 1.11.4
2026-02-07 14:27:47,815:INFO:              joblib: 1.3.2
2026-02-07 14:27:47,815:INFO:             sklearn: 1.4.2
2026-02-07 14:27:47,815:INFO:                pyod: 2.0.6
2026-02-07 14:27:47,815:INFO:            imblearn: 0.14.1
2026-02-07 14:27:47,816:INFO:   category_encoders: 2.7.0
2026-02-07 14:27:47,816:INFO:            lightgbm: 4.6.0
2026-02-07 14:27:47,816:INFO:               numba: 0.63.1
2026-02-07 14:27:47,816:INFO:            requests: 2.32.5
2026-02-07 14:27:47,816:INFO:          matplotlib: 3.7.5
2026-02-07 14:27:47,816:INFO:          scikitplot: 0.3.7
2026-02-07 14:27:47,816:INFO:         yellowbrick: 1.5
2026-02-07 14:27:47,816:INFO:              plotly: 6.5.2
2026-02-07 14:27:47,816:INFO:    plotly-resampler: Not installed
2026-02-07 14:27:47,816:INFO:             kaleido: 1.2.0
2026-02-07 14:27:47,816:INFO:           schemdraw: 0.15
2026-02-07 14:27:47,816:INFO:         statsmodels: 0.14.6
2026-02-07 14:27:47,816:INFO:              sktime: 0.26.0
2026-02-07 14:27:47,816:INFO:               tbats: 1.1.3
2026-02-07 14:27:47,816:INFO:            pmdarima: 2.0.4
2026-02-07 14:27:47,816:INFO:              psutil: 7.2.2
2026-02-07 14:27:47,816:INFO:          markupsafe: 3.0.3
2026-02-07 14:27:47,816:INFO:             pickle5: Not installed
2026-02-07 14:27:47,816:INFO:         cloudpickle: 3.1.2
2026-02-07 14:27:47,816:INFO:         deprecation: 2.1.0
2026-02-07 14:27:47,816:INFO:              xxhash: 3.6.0
2026-02-07 14:27:47,816:INFO:           wurlitzer: 3.1.1
2026-02-07 14:27:47,816:INFO:PyCaret optional dependencies:
2026-02-07 14:27:47,863:INFO:                shap: Not installed
2026-02-07 14:27:47,863:INFO:           interpret: Not installed
2026-02-07 14:27:47,863:INFO:                umap: Not installed
2026-02-07 14:27:47,863:INFO:     ydata_profiling: Not installed
2026-02-07 14:27:47,863:INFO:  explainerdashboard: Not installed
2026-02-07 14:27:47,863:INFO:             autoviz: Not installed
2026-02-07 14:27:47,863:INFO:           fairlearn: Not installed
2026-02-07 14:27:47,863:INFO:          deepchecks: Not installed
2026-02-07 14:27:47,863:INFO:             xgboost: Not installed
2026-02-07 14:27:47,863:INFO:            catboost: Not installed
2026-02-07 14:27:47,863:INFO:              kmodes: Not installed
2026-02-07 14:27:47,863:INFO:             mlxtend: Not installed
2026-02-07 14:27:47,863:INFO:       statsforecast: Not installed
2026-02-07 14:27:47,864:INFO:        tune_sklearn: Not installed
2026-02-07 14:27:47,864:INFO:                 ray: Not installed
2026-02-07 14:27:47,864:INFO:            hyperopt: Not installed
2026-02-07 14:27:47,864:INFO:              optuna: Not installed
2026-02-07 14:27:47,864:INFO:               skopt: Not installed
2026-02-07 14:27:47,864:INFO:              mlflow: Not installed
2026-02-07 14:27:47,864:INFO:              gradio: Not installed
2026-02-07 14:27:47,864:INFO:             fastapi: Not installed
2026-02-07 14:27:47,864:INFO:             uvicorn: Not installed
2026-02-07 14:27:47,864:INFO:              m2cgen: Not installed
2026-02-07 14:27:47,864:INFO:           evidently: Not installed
2026-02-07 14:27:47,864:INFO:               fugue: Not installed
2026-02-07 14:27:47,864:INFO:           streamlit: Not installed
2026-02-07 14:27:47,864:INFO:             prophet: Not installed
2026-02-07 14:27:47,864:INFO:None
2026-02-07 14:27:47,864:INFO:Set up data.
2026-02-07 14:27:47,874:INFO:Set up folding strategy.
2026-02-07 14:27:47,874:INFO:Set up train/test split.
2026-02-07 14:27:47,881:INFO:Set up index.
2026-02-07 14:27:47,882:INFO:Assigning column types.
2026-02-07 14:27:47,888:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-07 14:27:47,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-07 14:27:47,972:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-07 14:27:48,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,122:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-07 14:27:48,123:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-07 14:27:48,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,158:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-07 14:27:48,213:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-07 14:27:48,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,309:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-07 14:27:48,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,343:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-02-07 14:27:48,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:48,810:INFO:Preparing preprocessing pipeline...
2026-02-07 14:27:48,814:INFO:Set up simple imputation.
2026-02-07 14:27:48,880:INFO:Finished creating preprocessing pipeline.
2026-02-07 14:27:48,899:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['N', 'P', 'K', 'temperature',
                                             'humidity', 'ph', 'rainfall'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2026-02-07 14:27:48,899:INFO:Creating final display dataframe.
2026-02-07 14:27:49,060:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type        Multiclass
3           Original data shape         (2200, 8)
4        Transformed data shape         (2200, 8)
5   Transformed train set shape         (1540, 8)
6    Transformed test set shape          (660, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              05ee
2026-02-07 14:27:49,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:49,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:49,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:49,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-07 14:27:49,659:INFO:setup() successfully completed in 2.05s...............
2026-02-07 14:27:49,677:INFO:Initializing compare_models()
2026-02-07 14:27:49,677:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-02-07 14:27:49,677:INFO:Checking exceptions
2026-02-07 14:27:49,692:INFO:Preparing display monitor
2026-02-07 14:27:49,764:INFO:Initializing Logistic Regression
2026-02-07 14:27:49,765:INFO:Total runtime is 6.659825642903646e-06 minutes
2026-02-07 14:27:49,774:INFO:SubProcess create_model() called ==================================
2026-02-07 14:27:49,775:INFO:Initializing create_model()
2026-02-07 14:27:49,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:27:49,775:INFO:Checking exceptions
2026-02-07 14:27:49,775:INFO:Importing libraries
2026-02-07 14:27:49,775:INFO:Copying training dataset
2026-02-07 14:27:49,784:INFO:Defining folds
2026-02-07 14:27:49,785:INFO:Declaring metric variables
2026-02-07 14:27:49,793:INFO:Importing untrained model
2026-02-07 14:27:49,804:INFO:Logistic Regression Imported successfully
2026-02-07 14:27:49,822:INFO:Starting cross validation
2026-02-07 14:27:49,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:27:57,043:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:57,163:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:57,211:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:57,238:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:57,281:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:57,293:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:57,392:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:57,417:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:57,872:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:57,885:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:27:57,913:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:27:57,929:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:27:57,940:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:27:57,960:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:27:57,968:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:27:57,984:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:27:57,986:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:27:58,188:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:27:58,515:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:27:58,531:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:27:58,572:INFO:Calculating mean and std
2026-02-07 14:27:58,580:INFO:Creating metrics dataframe
2026-02-07 14:27:58,609:INFO:Uploading results into container
2026-02-07 14:27:58,611:INFO:Uploading model into container now
2026-02-07 14:27:58,613:INFO:_master_model_container: 1
2026-02-07 14:27:58,614:INFO:_display_container: 2
2026-02-07 14:27:58,615:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-02-07 14:27:58,615:INFO:create_model() successfully completed......................................
2026-02-07 14:27:58,970:INFO:SubProcess create_model() end ==================================
2026-02-07 14:27:58,970:INFO:Creating metrics dataframe
2026-02-07 14:27:58,983:INFO:Initializing K Neighbors Classifier
2026-02-07 14:27:58,983:INFO:Total runtime is 0.15364640951156616 minutes
2026-02-07 14:27:58,989:INFO:SubProcess create_model() called ==================================
2026-02-07 14:27:58,990:INFO:Initializing create_model()
2026-02-07 14:27:58,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:27:58,991:INFO:Checking exceptions
2026-02-07 14:27:58,991:INFO:Importing libraries
2026-02-07 14:27:58,991:INFO:Copying training dataset
2026-02-07 14:27:58,999:INFO:Defining folds
2026-02-07 14:27:59,000:INFO:Declaring metric variables
2026-02-07 14:27:59,010:INFO:Importing untrained model
2026-02-07 14:27:59,018:INFO:K Neighbors Classifier Imported successfully
2026-02-07 14:27:59,036:INFO:Starting cross validation
2026-02-07 14:27:59,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:02,422:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:28:02,462:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-07 14:28:02,773:INFO:Calculating mean and std
2026-02-07 14:28:02,776:INFO:Creating metrics dataframe
2026-02-07 14:28:02,781:INFO:Uploading results into container
2026-02-07 14:28:02,783:INFO:Uploading model into container now
2026-02-07 14:28:02,785:INFO:_master_model_container: 2
2026-02-07 14:28:02,785:INFO:_display_container: 2
2026-02-07 14:28:02,786:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2026-02-07 14:28:02,787:INFO:create_model() successfully completed......................................
2026-02-07 14:28:02,985:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:02,986:INFO:Creating metrics dataframe
2026-02-07 14:28:03,001:INFO:Initializing Naive Bayes
2026-02-07 14:28:03,001:INFO:Total runtime is 0.22061551809310914 minutes
2026-02-07 14:28:03,008:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:03,009:INFO:Initializing create_model()
2026-02-07 14:28:03,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:03,009:INFO:Checking exceptions
2026-02-07 14:28:03,009:INFO:Importing libraries
2026-02-07 14:28:03,009:INFO:Copying training dataset
2026-02-07 14:28:03,019:INFO:Defining folds
2026-02-07 14:28:03,019:INFO:Declaring metric variables
2026-02-07 14:28:03,026:INFO:Importing untrained model
2026-02-07 14:28:03,035:INFO:Naive Bayes Imported successfully
2026-02-07 14:28:03,052:INFO:Starting cross validation
2026-02-07 14:28:03,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:03,285:INFO:Calculating mean and std
2026-02-07 14:28:03,287:INFO:Creating metrics dataframe
2026-02-07 14:28:03,290:INFO:Uploading results into container
2026-02-07 14:28:03,292:INFO:Uploading model into container now
2026-02-07 14:28:03,293:INFO:_master_model_container: 3
2026-02-07 14:28:03,293:INFO:_display_container: 2
2026-02-07 14:28:03,293:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-07 14:28:03,293:INFO:create_model() successfully completed......................................
2026-02-07 14:28:03,462:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:03,462:INFO:Creating metrics dataframe
2026-02-07 14:28:03,480:INFO:Initializing Decision Tree Classifier
2026-02-07 14:28:03,480:INFO:Total runtime is 0.22860041856765748 minutes
2026-02-07 14:28:03,487:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:03,488:INFO:Initializing create_model()
2026-02-07 14:28:03,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:03,488:INFO:Checking exceptions
2026-02-07 14:28:03,488:INFO:Importing libraries
2026-02-07 14:28:03,488:INFO:Copying training dataset
2026-02-07 14:28:03,497:INFO:Defining folds
2026-02-07 14:28:03,498:INFO:Declaring metric variables
2026-02-07 14:28:03,504:INFO:Importing untrained model
2026-02-07 14:28:03,510:INFO:Decision Tree Classifier Imported successfully
2026-02-07 14:28:03,522:INFO:Starting cross validation
2026-02-07 14:28:03,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:03,823:INFO:Calculating mean and std
2026-02-07 14:28:03,826:INFO:Creating metrics dataframe
2026-02-07 14:28:03,832:INFO:Uploading results into container
2026-02-07 14:28:03,833:INFO:Uploading model into container now
2026-02-07 14:28:03,835:INFO:_master_model_container: 4
2026-02-07 14:28:03,835:INFO:_display_container: 2
2026-02-07 14:28:03,836:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2026-02-07 14:28:03,837:INFO:create_model() successfully completed......................................
2026-02-07 14:28:04,023:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:04,024:INFO:Creating metrics dataframe
2026-02-07 14:28:04,043:INFO:Initializing SVM - Linear Kernel
2026-02-07 14:28:04,044:INFO:Total runtime is 0.23799971739451092 minutes
2026-02-07 14:28:04,053:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:04,054:INFO:Initializing create_model()
2026-02-07 14:28:04,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:04,054:INFO:Checking exceptions
2026-02-07 14:28:04,054:INFO:Importing libraries
2026-02-07 14:28:04,054:INFO:Copying training dataset
2026-02-07 14:28:04,066:INFO:Defining folds
2026-02-07 14:28:04,066:INFO:Declaring metric variables
2026-02-07 14:28:04,075:INFO:Importing untrained model
2026-02-07 14:28:04,083:INFO:SVM - Linear Kernel Imported successfully
2026-02-07 14:28:04,099:INFO:Starting cross validation
2026-02-07 14:28:04,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:04,377:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,390:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,394:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,398:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,417:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,417:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,418:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,428:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,430:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,440:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,482:INFO:Calculating mean and std
2026-02-07 14:28:04,483:INFO:Creating metrics dataframe
2026-02-07 14:28:04,486:INFO:Uploading results into container
2026-02-07 14:28:04,487:INFO:Uploading model into container now
2026-02-07 14:28:04,489:INFO:_master_model_container: 5
2026-02-07 14:28:04,489:INFO:_display_container: 2
2026-02-07 14:28:04,490:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2026-02-07 14:28:04,491:INFO:create_model() successfully completed......................................
2026-02-07 14:28:04,695:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:04,696:INFO:Creating metrics dataframe
2026-02-07 14:28:04,723:INFO:Initializing Ridge Classifier
2026-02-07 14:28:04,724:INFO:Total runtime is 0.24932500123977663 minutes
2026-02-07 14:28:04,732:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:04,733:INFO:Initializing create_model()
2026-02-07 14:28:04,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:04,734:INFO:Checking exceptions
2026-02-07 14:28:04,734:INFO:Importing libraries
2026-02-07 14:28:04,734:INFO:Copying training dataset
2026-02-07 14:28:04,749:INFO:Defining folds
2026-02-07 14:28:04,750:INFO:Declaring metric variables
2026-02-07 14:28:04,760:INFO:Importing untrained model
2026-02-07 14:28:04,775:INFO:Ridge Classifier Imported successfully
2026-02-07 14:28:04,796:INFO:Starting cross validation
2026-02-07 14:28:04,798:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:04,902:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,903:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,904:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,912:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,919:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,920:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,921:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:04,922:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:04,923:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,924:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,926:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:04,930:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:04,933:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:04,940:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,940:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:04,941:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:04,942:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:04,943:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:04,957:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:04,959:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:04,989:INFO:Calculating mean and std
2026-02-07 14:28:04,991:INFO:Creating metrics dataframe
2026-02-07 14:28:04,995:INFO:Uploading results into container
2026-02-07 14:28:04,996:INFO:Uploading model into container now
2026-02-07 14:28:04,997:INFO:_master_model_container: 6
2026-02-07 14:28:04,997:INFO:_display_container: 2
2026-02-07 14:28:04,997:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2026-02-07 14:28:04,997:INFO:create_model() successfully completed......................................
2026-02-07 14:28:05,172:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:05,172:INFO:Creating metrics dataframe
2026-02-07 14:28:05,196:INFO:Initializing Random Forest Classifier
2026-02-07 14:28:05,196:INFO:Total runtime is 0.25719492435455327 minutes
2026-02-07 14:28:05,202:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:05,203:INFO:Initializing create_model()
2026-02-07 14:28:05,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:05,203:INFO:Checking exceptions
2026-02-07 14:28:05,203:INFO:Importing libraries
2026-02-07 14:28:05,204:INFO:Copying training dataset
2026-02-07 14:28:05,219:INFO:Defining folds
2026-02-07 14:28:05,220:INFO:Declaring metric variables
2026-02-07 14:28:05,227:INFO:Importing untrained model
2026-02-07 14:28:05,235:INFO:Random Forest Classifier Imported successfully
2026-02-07 14:28:05,254:INFO:Starting cross validation
2026-02-07 14:28:05,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:06,909:INFO:Calculating mean and std
2026-02-07 14:28:06,911:INFO:Creating metrics dataframe
2026-02-07 14:28:06,915:INFO:Uploading results into container
2026-02-07 14:28:06,916:INFO:Uploading model into container now
2026-02-07 14:28:06,917:INFO:_master_model_container: 7
2026-02-07 14:28:06,918:INFO:_display_container: 2
2026-02-07 14:28:06,918:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2026-02-07 14:28:06,919:INFO:create_model() successfully completed......................................
2026-02-07 14:28:07,098:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:07,099:INFO:Creating metrics dataframe
2026-02-07 14:28:07,122:INFO:Initializing Quadratic Discriminant Analysis
2026-02-07 14:28:07,122:INFO:Total runtime is 0.2892970720926921 minutes
2026-02-07 14:28:07,132:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:07,133:INFO:Initializing create_model()
2026-02-07 14:28:07,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:07,133:INFO:Checking exceptions
2026-02-07 14:28:07,133:INFO:Importing libraries
2026-02-07 14:28:07,134:INFO:Copying training dataset
2026-02-07 14:28:07,146:INFO:Defining folds
2026-02-07 14:28:07,146:INFO:Declaring metric variables
2026-02-07 14:28:07,159:INFO:Importing untrained model
2026-02-07 14:28:07,172:INFO:Quadratic Discriminant Analysis Imported successfully
2026-02-07 14:28:07,188:INFO:Starting cross validation
2026-02-07 14:28:07,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:07,309:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:07,310:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:07,319:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:07,328:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:07,330:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:07,334:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:07,366:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:07,368:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:07,416:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:07,428:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:07,465:INFO:Calculating mean and std
2026-02-07 14:28:07,467:INFO:Creating metrics dataframe
2026-02-07 14:28:07,471:INFO:Uploading results into container
2026-02-07 14:28:07,473:INFO:Uploading model into container now
2026-02-07 14:28:07,475:INFO:_master_model_container: 8
2026-02-07 14:28:07,476:INFO:_display_container: 2
2026-02-07 14:28:07,477:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2026-02-07 14:28:07,477:INFO:create_model() successfully completed......................................
2026-02-07 14:28:07,695:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:07,695:INFO:Creating metrics dataframe
2026-02-07 14:28:07,714:INFO:Initializing Ada Boost Classifier
2026-02-07 14:28:07,715:INFO:Total runtime is 0.2991735657056173 minutes
2026-02-07 14:28:07,726:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:07,727:INFO:Initializing create_model()
2026-02-07 14:28:07,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:07,727:INFO:Checking exceptions
2026-02-07 14:28:07,727:INFO:Importing libraries
2026-02-07 14:28:07,728:INFO:Copying training dataset
2026-02-07 14:28:07,744:INFO:Defining folds
2026-02-07 14:28:07,744:INFO:Declaring metric variables
2026-02-07 14:28:07,757:INFO:Importing untrained model
2026-02-07 14:28:07,770:INFO:Ada Boost Classifier Imported successfully
2026-02-07 14:28:07,791:INFO:Starting cross validation
2026-02-07 14:28:07,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:07,841:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-07 14:28:07,854:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-07 14:28:07,858:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-07 14:28:07,860:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-07 14:28:07,869:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-07 14:28:07,876:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-07 14:28:07,889:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-07 14:28:07,893:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-07 14:28:07,896:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-07 14:28:07,910:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-07 14:28:08,505:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:08,519:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:08,551:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:08,561:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:08,562:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:08,568:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:08,579:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:08,580:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:08,621:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:08,638:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:08,641:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:08,647:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:08,663:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:08,663:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:08,681:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:08,696:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:08,701:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:08,715:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:08,790:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:08,804:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:28:08,826:INFO:Calculating mean and std
2026-02-07 14:28:08,828:INFO:Creating metrics dataframe
2026-02-07 14:28:08,833:INFO:Uploading results into container
2026-02-07 14:28:08,835:INFO:Uploading model into container now
2026-02-07 14:28:08,836:INFO:_master_model_container: 9
2026-02-07 14:28:08,837:INFO:_display_container: 2
2026-02-07 14:28:08,837:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2026-02-07 14:28:08,837:INFO:create_model() successfully completed......................................
2026-02-07 14:28:09,028:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:09,029:INFO:Creating metrics dataframe
2026-02-07 14:28:09,068:INFO:Initializing Gradient Boosting Classifier
2026-02-07 14:28:09,069:INFO:Total runtime is 0.3217447638511658 minutes
2026-02-07 14:28:09,083:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:09,084:INFO:Initializing create_model()
2026-02-07 14:28:09,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:09,084:INFO:Checking exceptions
2026-02-07 14:28:09,084:INFO:Importing libraries
2026-02-07 14:28:09,084:INFO:Copying training dataset
2026-02-07 14:28:09,094:INFO:Defining folds
2026-02-07 14:28:09,094:INFO:Declaring metric variables
2026-02-07 14:28:09,102:INFO:Importing untrained model
2026-02-07 14:28:09,111:INFO:Gradient Boosting Classifier Imported successfully
2026-02-07 14:28:09,137:INFO:Starting cross validation
2026-02-07 14:28:09,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:36,665:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:36,871:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:36,909:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:37,172:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:37,215:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:37,241:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:37,308:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:37,426:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:37,521:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:37,612:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:37,634:INFO:Calculating mean and std
2026-02-07 14:28:37,636:INFO:Creating metrics dataframe
2026-02-07 14:28:37,640:INFO:Uploading results into container
2026-02-07 14:28:37,641:INFO:Uploading model into container now
2026-02-07 14:28:37,643:INFO:_master_model_container: 10
2026-02-07 14:28:37,643:INFO:_display_container: 2
2026-02-07 14:28:37,644:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2026-02-07 14:28:37,645:INFO:create_model() successfully completed......................................
2026-02-07 14:28:37,840:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:37,841:INFO:Creating metrics dataframe
2026-02-07 14:28:37,869:INFO:Initializing Linear Discriminant Analysis
2026-02-07 14:28:37,869:INFO:Total runtime is 0.801744814713796 minutes
2026-02-07 14:28:37,877:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:37,878:INFO:Initializing create_model()
2026-02-07 14:28:37,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:37,878:INFO:Checking exceptions
2026-02-07 14:28:37,879:INFO:Importing libraries
2026-02-07 14:28:37,879:INFO:Copying training dataset
2026-02-07 14:28:37,891:INFO:Defining folds
2026-02-07 14:28:37,892:INFO:Declaring metric variables
2026-02-07 14:28:37,900:INFO:Importing untrained model
2026-02-07 14:28:37,913:INFO:Linear Discriminant Analysis Imported successfully
2026-02-07 14:28:37,934:INFO:Starting cross validation
2026-02-07 14:28:37,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:38,017:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:38,019:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:38,024:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:38,034:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:38,036:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:38,046:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:38,054:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:38,058:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:38,067:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:38,068:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-07 14:28:38,104:INFO:Calculating mean and std
2026-02-07 14:28:38,107:INFO:Creating metrics dataframe
2026-02-07 14:28:38,111:INFO:Uploading results into container
2026-02-07 14:28:38,113:INFO:Uploading model into container now
2026-02-07 14:28:38,115:INFO:_master_model_container: 11
2026-02-07 14:28:38,115:INFO:_display_container: 2
2026-02-07 14:28:38,116:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2026-02-07 14:28:38,116:INFO:create_model() successfully completed......................................
2026-02-07 14:28:38,344:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:38,344:INFO:Creating metrics dataframe
2026-02-07 14:28:38,376:INFO:Initializing Extra Trees Classifier
2026-02-07 14:28:38,376:INFO:Total runtime is 0.8101985891660055 minutes
2026-02-07 14:28:38,389:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:38,390:INFO:Initializing create_model()
2026-02-07 14:28:38,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:38,391:INFO:Checking exceptions
2026-02-07 14:28:38,391:INFO:Importing libraries
2026-02-07 14:28:38,391:INFO:Copying training dataset
2026-02-07 14:28:38,403:INFO:Defining folds
2026-02-07 14:28:38,404:INFO:Declaring metric variables
2026-02-07 14:28:38,414:INFO:Importing untrained model
2026-02-07 14:28:38,429:INFO:Extra Trees Classifier Imported successfully
2026-02-07 14:28:38,456:INFO:Starting cross validation
2026-02-07 14:28:38,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:28:39,967:INFO:Calculating mean and std
2026-02-07 14:28:39,969:INFO:Creating metrics dataframe
2026-02-07 14:28:39,973:INFO:Uploading results into container
2026-02-07 14:28:39,975:INFO:Uploading model into container now
2026-02-07 14:28:39,976:INFO:_master_model_container: 12
2026-02-07 14:28:39,976:INFO:_display_container: 2
2026-02-07 14:28:39,977:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2026-02-07 14:28:39,977:INFO:create_model() successfully completed......................................
2026-02-07 14:28:40,165:INFO:SubProcess create_model() end ==================================
2026-02-07 14:28:40,166:INFO:Creating metrics dataframe
2026-02-07 14:28:40,183:INFO:Initializing Light Gradient Boosting Machine
2026-02-07 14:28:40,184:INFO:Total runtime is 0.8403240044911703 minutes
2026-02-07 14:28:40,190:INFO:SubProcess create_model() called ==================================
2026-02-07 14:28:40,190:INFO:Initializing create_model()
2026-02-07 14:28:40,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:28:40,190:INFO:Checking exceptions
2026-02-07 14:28:40,191:INFO:Importing libraries
2026-02-07 14:28:40,191:INFO:Copying training dataset
2026-02-07 14:28:40,204:INFO:Defining folds
2026-02-07 14:28:40,204:INFO:Declaring metric variables
2026-02-07 14:28:40,212:INFO:Importing untrained model
2026-02-07 14:28:40,220:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-07 14:28:40,234:INFO:Starting cross validation
2026-02-07 14:28:40,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:30:03,517:INFO:Calculating mean and std
2026-02-07 14:30:03,526:INFO:Creating metrics dataframe
2026-02-07 14:30:03,544:INFO:Uploading results into container
2026-02-07 14:30:03,546:INFO:Uploading model into container now
2026-02-07 14:30:03,551:INFO:_master_model_container: 13
2026-02-07 14:30:03,551:INFO:_display_container: 2
2026-02-07 14:30:03,556:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-02-07 14:30:03,556:INFO:create_model() successfully completed......................................
2026-02-07 14:30:04,507:INFO:SubProcess create_model() end ==================================
2026-02-07 14:30:04,508:INFO:Creating metrics dataframe
2026-02-07 14:30:04,540:INFO:Initializing Dummy Classifier
2026-02-07 14:30:04,540:INFO:Total runtime is 2.246263841787974 minutes
2026-02-07 14:30:04,547:INFO:SubProcess create_model() called ==================================
2026-02-07 14:30:04,548:INFO:Initializing create_model()
2026-02-07 14:30:04,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x79f2ecb67b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:30:04,549:INFO:Checking exceptions
2026-02-07 14:30:04,549:INFO:Importing libraries
2026-02-07 14:30:04,549:INFO:Copying training dataset
2026-02-07 14:30:04,570:INFO:Defining folds
2026-02-07 14:30:04,571:INFO:Declaring metric variables
2026-02-07 14:30:04,582:INFO:Importing untrained model
2026-02-07 14:30:04,594:INFO:Dummy Classifier Imported successfully
2026-02-07 14:30:04,615:INFO:Starting cross validation
2026-02-07 14:30:04,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-07 14:30:04,744:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:30:04,750:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:30:04,751:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:30:04,752:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:30:04,758:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:30:04,764:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:30:04,765:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:30:04,780:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:30:04,784:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:30:04,806:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-07 14:30:04,826:INFO:Calculating mean and std
2026-02-07 14:30:04,829:INFO:Creating metrics dataframe
2026-02-07 14:30:04,834:INFO:Uploading results into container
2026-02-07 14:30:04,835:INFO:Uploading model into container now
2026-02-07 14:30:04,837:INFO:_master_model_container: 14
2026-02-07 14:30:04,837:INFO:_display_container: 2
2026-02-07 14:30:04,837:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2026-02-07 14:30:04,837:INFO:create_model() successfully completed......................................
2026-02-07 14:30:05,044:INFO:SubProcess create_model() end ==================================
2026-02-07 14:30:05,045:INFO:Creating metrics dataframe
2026-02-07 14:30:05,098:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2026-02-07 14:30:05,124:INFO:Initializing create_model()
2026-02-07 14:30:05,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-07 14:30:05,125:INFO:Checking exceptions
2026-02-07 14:30:05,131:INFO:Importing libraries
2026-02-07 14:30:05,132:INFO:Copying training dataset
2026-02-07 14:30:05,144:INFO:Defining folds
2026-02-07 14:30:05,144:INFO:Declaring metric variables
2026-02-07 14:30:05,145:INFO:Importing untrained model
2026-02-07 14:30:05,145:INFO:Declaring custom model
2026-02-07 14:30:05,146:INFO:Random Forest Classifier Imported successfully
2026-02-07 14:30:05,147:INFO:Cross validation set to False
2026-02-07 14:30:05,147:INFO:Fitting Model
2026-02-07 14:30:05,685:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2026-02-07 14:30:05,685:INFO:create_model() successfully completed......................................
2026-02-07 14:30:05,936:INFO:_master_model_container: 14
2026-02-07 14:30:05,936:INFO:_display_container: 2
2026-02-07 14:30:05,937:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2026-02-07 14:30:05,938:INFO:compare_models() successfully completed......................................
2026-02-07 14:30:06,005:INFO:Initializing predict_model()
2026-02-07 14:30:06,005:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x79f2ecd42550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x79f2ece80c20>)
2026-02-07 14:30:06,006:INFO:Checking exceptions
2026-02-07 14:30:06,006:INFO:Preloading libraries
2026-02-07 14:30:06,011:INFO:Set up data.
2026-02-07 14:30:06,028:INFO:Set up index.
2026-02-07 14:39:51,991:INFO:Initializing save_model()
2026-02-07 14:39:51,991:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), model_name=/home/lucas/Documents/Estudos/End-to-End Farm detection/model/RandomForestClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['N', 'P', 'K', 'temperature',
                                             'humidity', 'ph', 'rainfall'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-02-07 14:39:51,992:INFO:Adding model into prep_pipe
2026-02-07 14:39:52,065:INFO:/home/lucas/Documents/Estudos/End-to-End Farm detection/model/RandomForestClassifier.pkl saved in current working directory
2026-02-07 14:39:52,073:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['N', 'P', 'K', 'temperature',
                                             'humidity', 'ph', 'rainfall'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=Non...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-02-07 14:39:52,073:INFO:save_model() successfully completed......................................
2026-02-08 18:03:49,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-08 18:03:49,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-08 18:03:49,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-08 18:03:49,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-08 20:18:27,908:INFO:PyCaret ClassificationExperiment
2026-02-08 20:18:27,911:INFO:Logging name: clf-default-name
2026-02-08 20:18:27,912:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-02-08 20:18:27,912:INFO:version 3.3.2
2026-02-08 20:18:27,912:INFO:Initializing setup()
2026-02-08 20:18:27,912:INFO:self.USI: 64a9
2026-02-08 20:18:27,912:INFO:self._variable_keys: {'exp_name_log', 'gpu_n_jobs_param', 'memory', 'exp_id', 'idx', 'y_test', '_ml_usecase', 'is_multiclass', 'USI', 'data', 'seed', 'X_test', 'fold_shuffle_param', 'X', 'target_param', 'html_param', 'X_train', 'gpu_param', 'pipeline', '_available_plots', 'fix_imbalance', 'logging_param', 'fold_generator', 'fold_groups_param', 'log_plots_param', 'n_jobs_param', 'y', 'y_train'}
2026-02-08 20:18:27,913:INFO:Checking environment
2026-02-08 20:18:27,914:INFO:python_version: 3.11.14
2026-02-08 20:18:27,914:INFO:python_build: ('main', 'Nov 19 2025 22:47:14')
2026-02-08 20:18:27,915:INFO:machine: x86_64
2026-02-08 20:18:27,916:INFO:platform: Linux-6.14.0-37-generic-x86_64-with-glibc2.39
2026-02-08 20:18:27,919:INFO:Memory: svmem(total=8011517952, available=1137463296, percent=85.8, used=6874054656, free=204087296, active=3388907520, inactive=3228340224, buffers=3850240, cached=1643606016, shared=1008304128, slab=494944256)
2026-02-08 20:18:27,928:INFO:Physical Core: 10
2026-02-08 20:18:27,928:INFO:Logical Core: 12
2026-02-08 20:18:27,928:INFO:Checking libraries
2026-02-08 20:18:27,929:INFO:System:
2026-02-08 20:18:27,929:INFO:    python: 3.11.14 (main, Nov 19 2025, 22:47:14) [Clang 21.1.4 ]
2026-02-08 20:18:27,929:INFO:executable: /home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/bin/python
2026-02-08 20:18:27,929:INFO:   machine: Linux-6.14.0-37-generic-x86_64-with-glibc2.39
2026-02-08 20:18:27,929:INFO:PyCaret required dependencies:
2026-02-08 20:18:27,965:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:28,700:INFO:                 pip: Not installed
2026-02-08 20:18:28,700:INFO:          setuptools: 81.0.0
2026-02-08 20:18:28,700:INFO:             pycaret: 3.3.2
2026-02-08 20:18:28,700:INFO:             IPython: 9.10.0
2026-02-08 20:18:28,700:INFO:          ipywidgets: 8.1.8
2026-02-08 20:18:28,700:INFO:                tqdm: 4.67.3
2026-02-08 20:18:28,700:INFO:               numpy: 1.26.4
2026-02-08 20:18:28,700:INFO:              pandas: 2.1.4
2026-02-08 20:18:28,700:INFO:              jinja2: 3.1.6
2026-02-08 20:18:28,700:INFO:               scipy: 1.11.4
2026-02-08 20:18:28,700:INFO:              joblib: 1.3.2
2026-02-08 20:18:28,700:INFO:             sklearn: 1.4.2
2026-02-08 20:18:28,700:INFO:                pyod: 2.0.6
2026-02-08 20:18:28,700:INFO:            imblearn: 0.14.1
2026-02-08 20:18:28,700:INFO:   category_encoders: 2.7.0
2026-02-08 20:18:28,700:INFO:            lightgbm: 4.6.0
2026-02-08 20:18:28,700:INFO:               numba: 0.63.1
2026-02-08 20:18:28,700:INFO:            requests: 2.32.5
2026-02-08 20:18:28,700:INFO:          matplotlib: 3.7.5
2026-02-08 20:18:28,700:INFO:          scikitplot: 0.3.7
2026-02-08 20:18:28,700:INFO:         yellowbrick: 1.5
2026-02-08 20:18:28,700:INFO:              plotly: 6.5.2
2026-02-08 20:18:28,700:INFO:    plotly-resampler: Not installed
2026-02-08 20:18:28,700:INFO:             kaleido: 1.2.0
2026-02-08 20:18:28,700:INFO:           schemdraw: 0.15
2026-02-08 20:18:28,700:INFO:         statsmodels: 0.14.6
2026-02-08 20:18:28,700:INFO:              sktime: 0.26.0
2026-02-08 20:18:28,700:INFO:               tbats: 1.1.3
2026-02-08 20:18:28,700:INFO:            pmdarima: 2.0.4
2026-02-08 20:18:28,700:INFO:              psutil: 7.2.2
2026-02-08 20:18:28,700:INFO:          markupsafe: 3.0.3
2026-02-08 20:18:28,700:INFO:             pickle5: Not installed
2026-02-08 20:18:28,700:INFO:         cloudpickle: 3.1.2
2026-02-08 20:18:28,701:INFO:         deprecation: 2.1.0
2026-02-08 20:18:28,701:INFO:              xxhash: 3.6.0
2026-02-08 20:18:28,701:INFO:           wurlitzer: 3.1.1
2026-02-08 20:18:28,701:INFO:PyCaret optional dependencies:
2026-02-08 20:18:28,767:INFO:                shap: Not installed
2026-02-08 20:18:28,767:INFO:           interpret: Not installed
2026-02-08 20:18:28,767:INFO:                umap: Not installed
2026-02-08 20:18:28,767:INFO:     ydata_profiling: Not installed
2026-02-08 20:18:28,767:INFO:  explainerdashboard: Not installed
2026-02-08 20:18:28,767:INFO:             autoviz: Not installed
2026-02-08 20:18:28,767:INFO:           fairlearn: Not installed
2026-02-08 20:18:28,767:INFO:          deepchecks: Not installed
2026-02-08 20:18:28,767:INFO:             xgboost: Not installed
2026-02-08 20:18:28,767:INFO:            catboost: Not installed
2026-02-08 20:18:28,767:INFO:              kmodes: Not installed
2026-02-08 20:18:28,767:INFO:             mlxtend: Not installed
2026-02-08 20:18:28,767:INFO:       statsforecast: Not installed
2026-02-08 20:18:28,767:INFO:        tune_sklearn: Not installed
2026-02-08 20:18:28,767:INFO:                 ray: Not installed
2026-02-08 20:18:28,767:INFO:            hyperopt: Not installed
2026-02-08 20:18:28,767:INFO:              optuna: Not installed
2026-02-08 20:18:28,767:INFO:               skopt: Not installed
2026-02-08 20:18:28,767:INFO:              mlflow: 3.9.0
2026-02-08 20:18:28,767:INFO:              gradio: Not installed
2026-02-08 20:18:28,767:INFO:             fastapi: 0.128.5
2026-02-08 20:18:28,767:INFO:             uvicorn: 0.40.0
2026-02-08 20:18:28,767:INFO:              m2cgen: Not installed
2026-02-08 20:18:28,767:INFO:           evidently: Not installed
2026-02-08 20:18:28,767:INFO:               fugue: Not installed
2026-02-08 20:18:28,767:INFO:           streamlit: Not installed
2026-02-08 20:18:28,767:INFO:             prophet: Not installed
2026-02-08 20:18:28,767:INFO:None
2026-02-08 20:18:28,767:INFO:Set up data.
2026-02-08 20:18:28,854:INFO:Set up folding strategy.
2026-02-08 20:18:28,856:INFO:Set up train/test split.
2026-02-08 20:18:28,868:INFO:Set up index.
2026-02-08 20:18:28,870:INFO:Assigning column types.
2026-02-08 20:18:28,880:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-08 20:18:28,914:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-08 20:18:28,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-08 20:18:28,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:28,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-08 20:18:29,026:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-08 20:18:29,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,039:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-08 20:18:29,058:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-08 20:18:29,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,090:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-08 20:18:29,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,103:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-02-08 20:18:29,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,189:INFO:Preparing preprocessing pipeline...
2026-02-08 20:18:29,192:INFO:Set up simple imputation.
2026-02-08 20:18:29,240:INFO:Finished creating preprocessing pipeline.
2026-02-08 20:18:29,244:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['N', 'P', 'K', 'temperature',
                                             'humidity', 'ph', 'rainfall'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2026-02-08 20:18:29,244:INFO:Creating final display dataframe.
2026-02-08 20:18:29,285:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type        Multiclass
3           Original data shape         (2200, 8)
4        Transformed data shape         (2200, 8)
5   Transformed train set shape         (1540, 8)
6    Transformed test set shape          (660, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              64a9
2026-02-08 20:18:29,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:18:29,435:INFO:setup() successfully completed in 1.6s...............
2026-02-08 20:18:32,600:INFO:Initializing compare_models()
2026-02-08 20:18:32,600:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-02-08 20:18:32,600:INFO:Checking exceptions
2026-02-08 20:18:32,607:INFO:Preparing display monitor
2026-02-08 20:18:32,693:INFO:Initializing Logistic Regression
2026-02-08 20:18:32,693:INFO:Total runtime is 6.854534149169922e-06 minutes
2026-02-08 20:18:32,698:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:32,701:INFO:Initializing create_model()
2026-02-08 20:18:32,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:32,701:INFO:Checking exceptions
2026-02-08 20:18:32,702:INFO:Importing libraries
2026-02-08 20:18:32,702:INFO:Copying training dataset
2026-02-08 20:18:32,707:INFO:Defining folds
2026-02-08 20:18:32,707:INFO:Declaring metric variables
2026-02-08 20:18:32,711:INFO:Importing untrained model
2026-02-08 20:18:32,715:INFO:Logistic Regression Imported successfully
2026-02-08 20:18:32,729:INFO:Starting cross validation
2026-02-08 20:18:32,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:36,750:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:36,750:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:36,750:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:36,750:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:36,750:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:36,750:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:36,750:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:36,750:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:36,751:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:36,751:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:37,131:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:37,132:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:37,132:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:37,136:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:37,141:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:37,147:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:37,148:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:37,149:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:37,151:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:37,172:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:37,329:INFO:Calculating mean and std
2026-02-08 20:18:37,404:INFO:Creating metrics dataframe
2026-02-08 20:18:37,546:INFO:Uploading results into container
2026-02-08 20:18:37,572:INFO:Uploading model into container now
2026-02-08 20:18:37,585:INFO:_master_model_container: 1
2026-02-08 20:18:37,586:INFO:_display_container: 2
2026-02-08 20:18:37,600:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-02-08 20:18:37,600:INFO:create_model() successfully completed......................................
2026-02-08 20:18:40,621:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:40,621:INFO:Creating metrics dataframe
2026-02-08 20:18:40,628:INFO:Initializing K Neighbors Classifier
2026-02-08 20:18:40,628:INFO:Total runtime is 0.13225124279658 minutes
2026-02-08 20:18:40,630:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:40,630:INFO:Initializing create_model()
2026-02-08 20:18:40,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:40,630:INFO:Checking exceptions
2026-02-08 20:18:40,630:INFO:Importing libraries
2026-02-08 20:18:40,631:INFO:Copying training dataset
2026-02-08 20:18:40,636:INFO:Defining folds
2026-02-08 20:18:40,636:INFO:Declaring metric variables
2026-02-08 20:18:40,637:INFO:Importing untrained model
2026-02-08 20:18:40,639:INFO:K Neighbors Classifier Imported successfully
2026-02-08 20:18:40,645:INFO:Starting cross validation
2026-02-08 20:18:40,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:42,022:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:42,025:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:18:42,156:INFO:Calculating mean and std
2026-02-08 20:18:42,158:INFO:Creating metrics dataframe
2026-02-08 20:18:42,161:INFO:Uploading results into container
2026-02-08 20:18:42,161:INFO:Uploading model into container now
2026-02-08 20:18:42,162:INFO:_master_model_container: 2
2026-02-08 20:18:42,162:INFO:_display_container: 2
2026-02-08 20:18:42,163:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2026-02-08 20:18:42,163:INFO:create_model() successfully completed......................................
2026-02-08 20:18:42,286:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:42,286:INFO:Creating metrics dataframe
2026-02-08 20:18:42,291:INFO:Initializing Naive Bayes
2026-02-08 20:18:42,291:INFO:Total runtime is 0.1599674383799235 minutes
2026-02-08 20:18:42,294:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:42,294:INFO:Initializing create_model()
2026-02-08 20:18:42,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:42,294:INFO:Checking exceptions
2026-02-08 20:18:42,294:INFO:Importing libraries
2026-02-08 20:18:42,294:INFO:Copying training dataset
2026-02-08 20:18:42,298:INFO:Defining folds
2026-02-08 20:18:42,298:INFO:Declaring metric variables
2026-02-08 20:18:42,301:INFO:Importing untrained model
2026-02-08 20:18:42,303:INFO:Naive Bayes Imported successfully
2026-02-08 20:18:42,310:INFO:Starting cross validation
2026-02-08 20:18:42,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:42,491:INFO:Calculating mean and std
2026-02-08 20:18:42,492:INFO:Creating metrics dataframe
2026-02-08 20:18:42,495:INFO:Uploading results into container
2026-02-08 20:18:42,496:INFO:Uploading model into container now
2026-02-08 20:18:42,497:INFO:_master_model_container: 3
2026-02-08 20:18:42,497:INFO:_display_container: 2
2026-02-08 20:18:42,498:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 20:18:42,498:INFO:create_model() successfully completed......................................
2026-02-08 20:18:42,609:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:42,609:INFO:Creating metrics dataframe
2026-02-08 20:18:42,615:INFO:Initializing Decision Tree Classifier
2026-02-08 20:18:42,615:INFO:Total runtime is 0.16536100705464682 minutes
2026-02-08 20:18:42,617:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:42,618:INFO:Initializing create_model()
2026-02-08 20:18:42,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:42,618:INFO:Checking exceptions
2026-02-08 20:18:42,618:INFO:Importing libraries
2026-02-08 20:18:42,618:INFO:Copying training dataset
2026-02-08 20:18:42,622:INFO:Defining folds
2026-02-08 20:18:42,622:INFO:Declaring metric variables
2026-02-08 20:18:42,625:INFO:Importing untrained model
2026-02-08 20:18:42,628:INFO:Decision Tree Classifier Imported successfully
2026-02-08 20:18:42,633:INFO:Starting cross validation
2026-02-08 20:18:42,634:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:42,744:INFO:Calculating mean and std
2026-02-08 20:18:42,745:INFO:Creating metrics dataframe
2026-02-08 20:18:42,747:INFO:Uploading results into container
2026-02-08 20:18:42,747:INFO:Uploading model into container now
2026-02-08 20:18:42,748:INFO:_master_model_container: 4
2026-02-08 20:18:42,748:INFO:_display_container: 2
2026-02-08 20:18:42,748:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2026-02-08 20:18:42,748:INFO:create_model() successfully completed......................................
2026-02-08 20:18:42,849:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:42,850:INFO:Creating metrics dataframe
2026-02-08 20:18:42,853:INFO:Initializing SVM - Linear Kernel
2026-02-08 20:18:42,853:INFO:Total runtime is 0.16933863162994386 minutes
2026-02-08 20:18:42,855:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:42,855:INFO:Initializing create_model()
2026-02-08 20:18:42,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:42,855:INFO:Checking exceptions
2026-02-08 20:18:42,855:INFO:Importing libraries
2026-02-08 20:18:42,855:INFO:Copying training dataset
2026-02-08 20:18:42,857:INFO:Defining folds
2026-02-08 20:18:42,857:INFO:Declaring metric variables
2026-02-08 20:18:42,859:INFO:Importing untrained model
2026-02-08 20:18:42,861:INFO:SVM - Linear Kernel Imported successfully
2026-02-08 20:18:42,865:INFO:Starting cross validation
2026-02-08 20:18:42,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:42,973:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:42,987:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:42,992:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:42,995:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:42,997:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:42,998:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,005:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,004:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,005:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,009:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,024:INFO:Calculating mean and std
2026-02-08 20:18:43,026:INFO:Creating metrics dataframe
2026-02-08 20:18:43,028:INFO:Uploading results into container
2026-02-08 20:18:43,028:INFO:Uploading model into container now
2026-02-08 20:18:43,029:INFO:_master_model_container: 5
2026-02-08 20:18:43,029:INFO:_display_container: 2
2026-02-08 20:18:43,030:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2026-02-08 20:18:43,030:INFO:create_model() successfully completed......................................
2026-02-08 20:18:43,137:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:43,137:INFO:Creating metrics dataframe
2026-02-08 20:18:43,141:INFO:Initializing Ridge Classifier
2026-02-08 20:18:43,141:INFO:Total runtime is 0.17413881222407024 minutes
2026-02-08 20:18:43,143:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:43,143:INFO:Initializing create_model()
2026-02-08 20:18:43,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:43,144:INFO:Checking exceptions
2026-02-08 20:18:43,144:INFO:Importing libraries
2026-02-08 20:18:43,144:INFO:Copying training dataset
2026-02-08 20:18:43,146:INFO:Defining folds
2026-02-08 20:18:43,146:INFO:Declaring metric variables
2026-02-08 20:18:43,148:INFO:Importing untrained model
2026-02-08 20:18:43,150:INFO:Ridge Classifier Imported successfully
2026-02-08 20:18:43,153:INFO:Starting cross validation
2026-02-08 20:18:43,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:43,187:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,186:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,189:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,194:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,195:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,195:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,196:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:43,196:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:43,198:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,199:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:43,201:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,201:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,202:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:43,203:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:43,204:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:43,204:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:43,205:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:43,209:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:43,211:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:43,212:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:43,231:INFO:Calculating mean and std
2026-02-08 20:18:43,232:INFO:Creating metrics dataframe
2026-02-08 20:18:43,235:INFO:Uploading results into container
2026-02-08 20:18:43,235:INFO:Uploading model into container now
2026-02-08 20:18:43,236:INFO:_master_model_container: 6
2026-02-08 20:18:43,236:INFO:_display_container: 2
2026-02-08 20:18:43,237:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2026-02-08 20:18:43,237:INFO:create_model() successfully completed......................................
2026-02-08 20:18:43,355:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:43,355:INFO:Creating metrics dataframe
2026-02-08 20:18:43,360:INFO:Initializing Random Forest Classifier
2026-02-08 20:18:43,360:INFO:Total runtime is 0.17778703769048057 minutes
2026-02-08 20:18:43,362:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:43,363:INFO:Initializing create_model()
2026-02-08 20:18:43,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:43,363:INFO:Checking exceptions
2026-02-08 20:18:43,363:INFO:Importing libraries
2026-02-08 20:18:43,363:INFO:Copying training dataset
2026-02-08 20:18:43,367:INFO:Defining folds
2026-02-08 20:18:43,368:INFO:Declaring metric variables
2026-02-08 20:18:43,371:INFO:Importing untrained model
2026-02-08 20:18:43,374:INFO:Random Forest Classifier Imported successfully
2026-02-08 20:18:43,381:INFO:Starting cross validation
2026-02-08 20:18:43,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:44,189:INFO:Calculating mean and std
2026-02-08 20:18:44,190:INFO:Creating metrics dataframe
2026-02-08 20:18:44,192:INFO:Uploading results into container
2026-02-08 20:18:44,192:INFO:Uploading model into container now
2026-02-08 20:18:44,193:INFO:_master_model_container: 7
2026-02-08 20:18:44,193:INFO:_display_container: 2
2026-02-08 20:18:44,193:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2026-02-08 20:18:44,193:INFO:create_model() successfully completed......................................
2026-02-08 20:18:44,295:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:44,296:INFO:Creating metrics dataframe
2026-02-08 20:18:44,300:INFO:Initializing Quadratic Discriminant Analysis
2026-02-08 20:18:44,300:INFO:Total runtime is 0.19345020850499473 minutes
2026-02-08 20:18:44,302:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:44,302:INFO:Initializing create_model()
2026-02-08 20:18:44,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:44,302:INFO:Checking exceptions
2026-02-08 20:18:44,302:INFO:Importing libraries
2026-02-08 20:18:44,302:INFO:Copying training dataset
2026-02-08 20:18:44,304:INFO:Defining folds
2026-02-08 20:18:44,304:INFO:Declaring metric variables
2026-02-08 20:18:44,306:INFO:Importing untrained model
2026-02-08 20:18:44,307:INFO:Quadratic Discriminant Analysis Imported successfully
2026-02-08 20:18:44,311:INFO:Starting cross validation
2026-02-08 20:18:44,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:44,347:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,349:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,350:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,351:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,355:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,355:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,356:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,361:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,372:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,377:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,398:INFO:Calculating mean and std
2026-02-08 20:18:44,399:INFO:Creating metrics dataframe
2026-02-08 20:18:44,401:INFO:Uploading results into container
2026-02-08 20:18:44,401:INFO:Uploading model into container now
2026-02-08 20:18:44,402:INFO:_master_model_container: 8
2026-02-08 20:18:44,402:INFO:_display_container: 2
2026-02-08 20:18:44,402:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2026-02-08 20:18:44,402:INFO:create_model() successfully completed......................................
2026-02-08 20:18:44,607:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:44,607:INFO:Creating metrics dataframe
2026-02-08 20:18:44,628:INFO:Initializing Ada Boost Classifier
2026-02-08 20:18:44,628:INFO:Total runtime is 0.1989231109619141 minutes
2026-02-08 20:18:44,632:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:44,632:INFO:Initializing create_model()
2026-02-08 20:18:44,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:44,632:INFO:Checking exceptions
2026-02-08 20:18:44,632:INFO:Importing libraries
2026-02-08 20:18:44,632:INFO:Copying training dataset
2026-02-08 20:18:44,637:INFO:Defining folds
2026-02-08 20:18:44,637:INFO:Declaring metric variables
2026-02-08 20:18:44,640:INFO:Importing untrained model
2026-02-08 20:18:44,643:INFO:Ada Boost Classifier Imported successfully
2026-02-08 20:18:44,650:INFO:Starting cross validation
2026-02-08 20:18:44,651:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:44,680:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:18:44,681:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:18:44,682:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:18:44,686:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:18:44,686:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:18:44,687:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:18:44,689:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:18:44,691:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:18:44,692:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:18:44,694:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:18:44,947:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,952:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:44,955:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,960:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,960:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:44,961:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,963:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,964:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:44,965:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,967:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:44,968:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:44,969:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,970:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:44,972:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,975:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:44,976:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,976:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:44,977:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:44,981:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:44,983:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:18:44,996:INFO:Calculating mean and std
2026-02-08 20:18:44,996:INFO:Creating metrics dataframe
2026-02-08 20:18:44,998:INFO:Uploading results into container
2026-02-08 20:18:44,999:INFO:Uploading model into container now
2026-02-08 20:18:44,999:INFO:_master_model_container: 9
2026-02-08 20:18:44,999:INFO:_display_container: 2
2026-02-08 20:18:44,999:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2026-02-08 20:18:44,999:INFO:create_model() successfully completed......................................
2026-02-08 20:18:45,110:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:45,110:INFO:Creating metrics dataframe
2026-02-08 20:18:45,115:INFO:Initializing Gradient Boosting Classifier
2026-02-08 20:18:45,115:INFO:Total runtime is 0.2070402542750041 minutes
2026-02-08 20:18:45,117:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:45,117:INFO:Initializing create_model()
2026-02-08 20:18:45,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:45,118:INFO:Checking exceptions
2026-02-08 20:18:45,118:INFO:Importing libraries
2026-02-08 20:18:45,118:INFO:Copying training dataset
2026-02-08 20:18:45,120:INFO:Defining folds
2026-02-08 20:18:45,120:INFO:Declaring metric variables
2026-02-08 20:18:45,122:INFO:Importing untrained model
2026-02-08 20:18:45,124:INFO:Gradient Boosting Classifier Imported successfully
2026-02-08 20:18:45,130:INFO:Starting cross validation
2026-02-08 20:18:45,131:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:57,438:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:57,481:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:57,553:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:57,682:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:57,739:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:57,811:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:57,816:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:57,912:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:57,974:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,116:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,125:INFO:Calculating mean and std
2026-02-08 20:18:58,126:INFO:Creating metrics dataframe
2026-02-08 20:18:58,128:INFO:Uploading results into container
2026-02-08 20:18:58,128:INFO:Uploading model into container now
2026-02-08 20:18:58,128:INFO:_master_model_container: 10
2026-02-08 20:18:58,128:INFO:_display_container: 2
2026-02-08 20:18:58,129:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2026-02-08 20:18:58,129:INFO:create_model() successfully completed......................................
2026-02-08 20:18:58,239:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:58,239:INFO:Creating metrics dataframe
2026-02-08 20:18:58,244:INFO:Initializing Linear Discriminant Analysis
2026-02-08 20:18:58,244:INFO:Total runtime is 0.4258449633916219 minutes
2026-02-08 20:18:58,245:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:58,245:INFO:Initializing create_model()
2026-02-08 20:18:58,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:58,246:INFO:Checking exceptions
2026-02-08 20:18:58,246:INFO:Importing libraries
2026-02-08 20:18:58,246:INFO:Copying training dataset
2026-02-08 20:18:58,248:INFO:Defining folds
2026-02-08 20:18:58,248:INFO:Declaring metric variables
2026-02-08 20:18:58,249:INFO:Importing untrained model
2026-02-08 20:18:58,252:INFO:Linear Discriminant Analysis Imported successfully
2026-02-08 20:18:58,255:INFO:Starting cross validation
2026-02-08 20:18:58,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:58,299:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,299:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,301:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,308:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,308:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,311:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,313:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,315:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,321:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,325:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:18:58,342:INFO:Calculating mean and std
2026-02-08 20:18:58,342:INFO:Creating metrics dataframe
2026-02-08 20:18:58,344:INFO:Uploading results into container
2026-02-08 20:18:58,345:INFO:Uploading model into container now
2026-02-08 20:18:58,345:INFO:_master_model_container: 11
2026-02-08 20:18:58,345:INFO:_display_container: 2
2026-02-08 20:18:58,345:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2026-02-08 20:18:58,345:INFO:create_model() successfully completed......................................
2026-02-08 20:18:58,459:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:58,459:INFO:Creating metrics dataframe
2026-02-08 20:18:58,464:INFO:Initializing Extra Trees Classifier
2026-02-08 20:18:58,464:INFO:Total runtime is 0.42951026757558186 minutes
2026-02-08 20:18:58,465:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:58,465:INFO:Initializing create_model()
2026-02-08 20:18:58,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:58,466:INFO:Checking exceptions
2026-02-08 20:18:58,466:INFO:Importing libraries
2026-02-08 20:18:58,466:INFO:Copying training dataset
2026-02-08 20:18:58,468:INFO:Defining folds
2026-02-08 20:18:58,468:INFO:Declaring metric variables
2026-02-08 20:18:58,470:INFO:Importing untrained model
2026-02-08 20:18:58,472:INFO:Extra Trees Classifier Imported successfully
2026-02-08 20:18:58,476:INFO:Starting cross validation
2026-02-08 20:18:58,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:18:59,088:INFO:Calculating mean and std
2026-02-08 20:18:59,089:INFO:Creating metrics dataframe
2026-02-08 20:18:59,090:INFO:Uploading results into container
2026-02-08 20:18:59,090:INFO:Uploading model into container now
2026-02-08 20:18:59,091:INFO:_master_model_container: 12
2026-02-08 20:18:59,091:INFO:_display_container: 2
2026-02-08 20:18:59,092:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2026-02-08 20:18:59,092:INFO:create_model() successfully completed......................................
2026-02-08 20:18:59,196:INFO:SubProcess create_model() end ==================================
2026-02-08 20:18:59,196:INFO:Creating metrics dataframe
2026-02-08 20:18:59,201:INFO:Initializing Light Gradient Boosting Machine
2026-02-08 20:18:59,201:INFO:Total runtime is 0.4417967478434245 minutes
2026-02-08 20:18:59,202:INFO:SubProcess create_model() called ==================================
2026-02-08 20:18:59,203:INFO:Initializing create_model()
2026-02-08 20:18:59,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:18:59,203:INFO:Checking exceptions
2026-02-08 20:18:59,203:INFO:Importing libraries
2026-02-08 20:18:59,203:INFO:Copying training dataset
2026-02-08 20:18:59,205:INFO:Defining folds
2026-02-08 20:18:59,205:INFO:Declaring metric variables
2026-02-08 20:18:59,206:INFO:Importing untrained model
2026-02-08 20:18:59,208:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-08 20:18:59,212:INFO:Starting cross validation
2026-02-08 20:18:59,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:19:41,026:INFO:Calculating mean and std
2026-02-08 20:19:41,036:INFO:Creating metrics dataframe
2026-02-08 20:19:41,054:INFO:Uploading results into container
2026-02-08 20:19:41,059:INFO:Uploading model into container now
2026-02-08 20:19:41,063:INFO:_master_model_container: 13
2026-02-08 20:19:41,063:INFO:_display_container: 2
2026-02-08 20:19:41,070:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-02-08 20:19:41,070:INFO:create_model() successfully completed......................................
2026-02-08 20:19:41,904:INFO:SubProcess create_model() end ==================================
2026-02-08 20:19:41,904:INFO:Creating metrics dataframe
2026-02-08 20:19:41,911:INFO:Initializing Dummy Classifier
2026-02-08 20:19:41,911:INFO:Total runtime is 1.1536282658576966 minutes
2026-02-08 20:19:41,913:INFO:SubProcess create_model() called ==================================
2026-02-08 20:19:41,913:INFO:Initializing create_model()
2026-02-08 20:19:41,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed0c78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:19:41,913:INFO:Checking exceptions
2026-02-08 20:19:41,913:INFO:Importing libraries
2026-02-08 20:19:41,913:INFO:Copying training dataset
2026-02-08 20:19:41,916:INFO:Defining folds
2026-02-08 20:19:41,916:INFO:Declaring metric variables
2026-02-08 20:19:41,918:INFO:Importing untrained model
2026-02-08 20:19:41,919:INFO:Dummy Classifier Imported successfully
2026-02-08 20:19:41,922:INFO:Starting cross validation
2026-02-08 20:19:41,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:19:42,004:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:19:42,004:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:19:42,007:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:19:42,010:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:19:42,012:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:19:42,012:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:19:42,014:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:19:42,016:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:19:42,032:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:19:42,093:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:19:42,108:INFO:Calculating mean and std
2026-02-08 20:19:42,109:INFO:Creating metrics dataframe
2026-02-08 20:19:42,112:INFO:Uploading results into container
2026-02-08 20:19:42,113:INFO:Uploading model into container now
2026-02-08 20:19:42,113:INFO:_master_model_container: 14
2026-02-08 20:19:42,114:INFO:_display_container: 2
2026-02-08 20:19:42,114:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2026-02-08 20:19:42,114:INFO:create_model() successfully completed......................................
2026-02-08 20:19:42,229:INFO:SubProcess create_model() end ==================================
2026-02-08 20:19:42,230:INFO:Creating metrics dataframe
2026-02-08 20:19:42,243:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2026-02-08 20:19:42,251:INFO:Initializing create_model()
2026-02-08 20:19:42,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:19:42,251:INFO:Checking exceptions
2026-02-08 20:19:42,255:INFO:Importing libraries
2026-02-08 20:19:42,255:INFO:Copying training dataset
2026-02-08 20:19:42,259:INFO:Defining folds
2026-02-08 20:19:42,259:INFO:Declaring metric variables
2026-02-08 20:19:42,260:INFO:Importing untrained model
2026-02-08 20:19:42,260:INFO:Declaring custom model
2026-02-08 20:19:42,260:INFO:Random Forest Classifier Imported successfully
2026-02-08 20:19:42,261:INFO:Cross validation set to False
2026-02-08 20:19:42,261:INFO:Fitting Model
2026-02-08 20:19:42,575:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2026-02-08 20:19:42,575:INFO:create_model() successfully completed......................................
2026-02-08 20:19:42,752:INFO:_master_model_container: 14
2026-02-08 20:19:42,752:INFO:_display_container: 2
2026-02-08 20:19:42,753:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2026-02-08 20:19:42,753:INFO:compare_models() successfully completed......................................
2026-02-08 20:19:42,875:INFO:Initializing predict_model()
2026-02-08 20:19:42,875:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7e78ecb73240>)
2026-02-08 20:19:42,875:INFO:Checking exceptions
2026-02-08 20:19:42,875:INFO:Preloading libraries
2026-02-08 20:19:42,878:INFO:Set up data.
2026-02-08 20:19:42,887:INFO:Set up index.
2026-02-08 20:21:06,394:INFO:Initializing evaluate_model()
2026-02-08 20:21:06,394:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-02-08 20:21:06,400:INFO:Initializing plot_model()
2026-02-08 20:21:06,401:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:21:06,401:INFO:Checking exceptions
2026-02-08 20:21:06,416:INFO:Preloading libraries
2026-02-08 20:21:06,495:INFO:Copying training dataset
2026-02-08 20:21:06,496:INFO:Plot type: pipeline
2026-02-08 20:21:06,752:INFO:Visual Rendered Successfully
2026-02-08 20:21:06,906:INFO:plot_model() successfully completed......................................
2026-02-08 20:21:10,611:INFO:Initializing plot_model()
2026-02-08 20:21:10,611:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:21:10,611:INFO:Checking exceptions
2026-02-08 20:21:10,627:INFO:Preloading libraries
2026-02-08 20:21:10,635:INFO:Copying training dataset
2026-02-08 20:21:10,635:INFO:Plot type: feature
2026-02-08 20:21:10,636:WARNING:No coef_ found. Trying feature_importances_
2026-02-08 20:21:10,729:INFO:Visual Rendered Successfully
2026-02-08 20:21:10,853:INFO:plot_model() successfully completed......................................
2026-02-08 20:21:15,763:INFO:Initializing plot_model()
2026-02-08 20:21:15,763:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:21:15,763:INFO:Checking exceptions
2026-02-08 20:21:15,776:INFO:Preloading libraries
2026-02-08 20:21:15,780:INFO:Copying training dataset
2026-02-08 20:21:15,780:INFO:Plot type: feature_all
2026-02-08 20:21:15,788:WARNING:No coef_ found. Trying feature_importances_
2026-02-08 20:21:15,845:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/matplotlib/_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2026-02-08 20:21:15,846:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/matplotlib/_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2026-02-08 20:21:15,847:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/matplotlib/patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2026-02-08 20:21:15,848:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/matplotlib/transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2026-02-08 20:21:15,868:INFO:Visual Rendered Successfully
2026-02-08 20:21:16,008:INFO:plot_model() successfully completed......................................
2026-02-08 20:21:17,608:INFO:Initializing plot_model()
2026-02-08 20:21:17,608:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:21:17,608:INFO:Checking exceptions
2026-02-08 20:21:17,626:INFO:Preloading libraries
2026-02-08 20:21:17,630:INFO:Copying training dataset
2026-02-08 20:21:17,630:INFO:Plot type: feature
2026-02-08 20:21:17,630:WARNING:No coef_ found. Trying feature_importances_
2026-02-08 20:21:17,707:INFO:Visual Rendered Successfully
2026-02-08 20:21:17,832:INFO:plot_model() successfully completed......................................
2026-02-08 20:21:20,150:INFO:Initializing plot_model()
2026-02-08 20:21:20,150:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:21:20,150:INFO:Checking exceptions
2026-02-08 20:21:20,164:INFO:Preloading libraries
2026-02-08 20:21:20,168:INFO:Copying training dataset
2026-02-08 20:21:20,168:INFO:Plot type: auc
2026-02-08 20:21:20,196:INFO:Fitting Model
2026-02-08 20:21:20,196:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2026-02-08 20:21:20,197:INFO:Scoring test/hold-out set
2026-02-08 20:21:20,462:INFO:Visual Rendered Successfully
2026-02-08 20:21:20,595:INFO:plot_model() successfully completed......................................
2026-02-08 20:21:23,565:INFO:Initializing plot_model()
2026-02-08 20:21:23,565:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:21:23,565:INFO:Checking exceptions
2026-02-08 20:21:23,580:INFO:Preloading libraries
2026-02-08 20:21:23,584:INFO:Copying training dataset
2026-02-08 20:21:23,584:INFO:Plot type: feature
2026-02-08 20:21:23,584:WARNING:No coef_ found. Trying feature_importances_
2026-02-08 20:21:23,661:INFO:Visual Rendered Successfully
2026-02-08 20:21:23,795:INFO:plot_model() successfully completed......................................
2026-02-08 20:21:26,806:INFO:Initializing plot_model()
2026-02-08 20:21:26,806:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:21:26,806:INFO:Checking exceptions
2026-02-08 20:21:26,820:INFO:Preloading libraries
2026-02-08 20:21:26,825:INFO:Copying training dataset
2026-02-08 20:21:26,825:INFO:Plot type: tree
2026-02-08 20:21:27,530:INFO:Plotting decision trees
2026-02-08 20:21:39,129:INFO:Initializing evaluate_model()
2026-02-08 20:21:39,130:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-02-08 20:21:39,137:INFO:Initializing plot_model()
2026-02-08 20:21:39,137:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:21:39,137:INFO:Checking exceptions
2026-02-08 20:21:39,169:INFO:Preloading libraries
2026-02-08 20:21:39,209:INFO:Copying training dataset
2026-02-08 20:21:39,210:INFO:Plot type: pipeline
2026-02-08 20:21:39,332:INFO:Visual Rendered Successfully
2026-02-08 20:21:39,604:INFO:plot_model() successfully completed......................................
2026-02-08 20:21:39,611:INFO:Initializing plot_model()
2026-02-08 20:21:39,611:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:21:39,611:INFO:Checking exceptions
2026-02-08 20:21:39,627:INFO:Preloading libraries
2026-02-08 20:21:39,647:INFO:Copying training dataset
2026-02-08 20:21:39,647:INFO:Plot type: feature
2026-02-08 20:21:39,648:WARNING:No coef_ found. Trying feature_importances_
2026-02-08 20:21:39,757:INFO:Visual Rendered Successfully
2026-02-08 20:21:40,003:INFO:plot_model() successfully completed......................................
2026-02-08 20:21:41,971:INFO:Initializing plot_model()
2026-02-08 20:21:41,971:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:21:41,971:INFO:Checking exceptions
2026-02-08 20:21:41,987:INFO:Preloading libraries
2026-02-08 20:21:41,990:INFO:Copying training dataset
2026-02-08 20:21:41,991:INFO:Plot type: feature
2026-02-08 20:21:41,991:WARNING:No coef_ found. Trying feature_importances_
2026-02-08 20:21:42,109:INFO:Visual Rendered Successfully
2026-02-08 20:21:42,308:INFO:plot_model() successfully completed......................................
2026-02-08 20:24:33,773:INFO:Initializing plot_model()
2026-02-08 20:24:33,774:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:24:33,774:INFO:Checking exceptions
2026-02-08 20:24:38,934:INFO:Initializing plot_model()
2026-02-08 20:24:38,934:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 20:24:38,934:INFO:Checking exceptions
2026-02-08 20:24:38,993:INFO:Preloading libraries
2026-02-08 20:24:39,074:INFO:Copying training dataset
2026-02-08 20:24:39,074:INFO:Plot type: parameter
2026-02-08 20:24:39,080:INFO:Visual Rendered Successfully
2026-02-08 20:24:39,675:INFO:plot_model() successfully completed......................................
2026-02-08 20:26:07,484:INFO:Initializing tune_model()
2026-02-08 20:26:07,485:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e78ed0bf7d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-02-08 20:26:07,485:INFO:Checking exceptions
2026-02-08 20:26:07,500:INFO:Copying training dataset
2026-02-08 20:26:07,503:INFO:Checking base model
2026-02-08 20:26:07,503:INFO:Base model : Random Forest Classifier
2026-02-08 20:26:07,507:INFO:Declaring metric variables
2026-02-08 20:26:07,511:INFO:Defining Hyperparameters
2026-02-08 20:26:07,641:INFO:Tuning with n_jobs=-1
2026-02-08 20:26:07,641:INFO:Initializing RandomizedSearchCV
2026-02-08 20:26:11,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,917:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,919:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,922:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,923:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:26:11,923:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:33:59,694:INFO:PyCaret ClassificationExperiment
2026-02-08 20:33:59,695:INFO:Logging name: clf-default-name
2026-02-08 20:33:59,695:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-02-08 20:33:59,695:INFO:version 3.3.2
2026-02-08 20:33:59,695:INFO:Initializing setup()
2026-02-08 20:33:59,695:INFO:self.USI: eefe
2026-02-08 20:33:59,695:INFO:self._variable_keys: {'exp_name_log', 'gpu_n_jobs_param', 'memory', 'exp_id', 'idx', 'y_test', '_ml_usecase', 'is_multiclass', 'USI', 'data', 'seed', 'X_test', 'fold_shuffle_param', 'X', 'target_param', 'html_param', 'X_train', 'gpu_param', 'pipeline', '_available_plots', 'fix_imbalance', 'logging_param', 'fold_generator', 'fold_groups_param', 'log_plots_param', 'n_jobs_param', 'y', 'y_train'}
2026-02-08 20:33:59,695:INFO:Checking environment
2026-02-08 20:33:59,695:INFO:python_version: 3.11.14
2026-02-08 20:33:59,695:INFO:python_build: ('main', 'Nov 19 2025 22:47:14')
2026-02-08 20:33:59,695:INFO:machine: x86_64
2026-02-08 20:33:59,695:INFO:platform: Linux-6.14.0-37-generic-x86_64-with-glibc2.39
2026-02-08 20:33:59,695:INFO:Memory: svmem(total=8011517952, available=1192071168, percent=85.1, used=6819446784, free=289406976, active=3878215680, inactive=2667438080, buffers=5505024, cached=1301704704, shared=682856448, slab=490479616)
2026-02-08 20:33:59,696:INFO:Physical Core: 10
2026-02-08 20:33:59,696:INFO:Logical Core: 12
2026-02-08 20:33:59,696:INFO:Checking libraries
2026-02-08 20:33:59,696:INFO:System:
2026-02-08 20:33:59,696:INFO:    python: 3.11.14 (main, Nov 19 2025, 22:47:14) [Clang 21.1.4 ]
2026-02-08 20:33:59,696:INFO:executable: /home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/bin/python
2026-02-08 20:33:59,696:INFO:   machine: Linux-6.14.0-37-generic-x86_64-with-glibc2.39
2026-02-08 20:33:59,696:INFO:PyCaret required dependencies:
2026-02-08 20:33:59,696:INFO:                 pip: Not installed
2026-02-08 20:33:59,696:INFO:          setuptools: 81.0.0
2026-02-08 20:33:59,696:INFO:             pycaret: 3.3.2
2026-02-08 20:33:59,696:INFO:             IPython: 9.10.0
2026-02-08 20:33:59,696:INFO:          ipywidgets: 8.1.8
2026-02-08 20:33:59,696:INFO:                tqdm: 4.67.3
2026-02-08 20:33:59,696:INFO:               numpy: 1.26.4
2026-02-08 20:33:59,697:INFO:              pandas: 2.1.4
2026-02-08 20:33:59,697:INFO:              jinja2: 3.1.6
2026-02-08 20:33:59,697:INFO:               scipy: 1.11.4
2026-02-08 20:33:59,697:INFO:              joblib: 1.3.2
2026-02-08 20:33:59,697:INFO:             sklearn: 1.4.2
2026-02-08 20:33:59,697:INFO:                pyod: 2.0.6
2026-02-08 20:33:59,697:INFO:            imblearn: 0.14.1
2026-02-08 20:33:59,697:INFO:   category_encoders: 2.7.0
2026-02-08 20:33:59,697:INFO:            lightgbm: 4.6.0
2026-02-08 20:33:59,697:INFO:               numba: 0.63.1
2026-02-08 20:33:59,697:INFO:            requests: 2.32.5
2026-02-08 20:33:59,697:INFO:          matplotlib: 3.7.5
2026-02-08 20:33:59,697:INFO:          scikitplot: 0.3.7
2026-02-08 20:33:59,697:INFO:         yellowbrick: 1.5
2026-02-08 20:33:59,697:INFO:              plotly: 6.5.2
2026-02-08 20:33:59,697:INFO:    plotly-resampler: Not installed
2026-02-08 20:33:59,697:INFO:             kaleido: 1.2.0
2026-02-08 20:33:59,697:INFO:           schemdraw: 0.15
2026-02-08 20:33:59,697:INFO:         statsmodels: 0.14.6
2026-02-08 20:33:59,697:INFO:              sktime: 0.26.0
2026-02-08 20:33:59,697:INFO:               tbats: 1.1.3
2026-02-08 20:33:59,697:INFO:            pmdarima: 2.0.4
2026-02-08 20:33:59,697:INFO:              psutil: 7.2.2
2026-02-08 20:33:59,698:INFO:          markupsafe: 3.0.3
2026-02-08 20:33:59,698:INFO:             pickle5: Not installed
2026-02-08 20:33:59,698:INFO:         cloudpickle: 3.1.2
2026-02-08 20:33:59,698:INFO:         deprecation: 2.1.0
2026-02-08 20:33:59,698:INFO:              xxhash: 3.6.0
2026-02-08 20:33:59,698:INFO:           wurlitzer: 3.1.1
2026-02-08 20:33:59,698:INFO:PyCaret optional dependencies:
2026-02-08 20:33:59,698:INFO:                shap: Not installed
2026-02-08 20:33:59,698:INFO:           interpret: Not installed
2026-02-08 20:33:59,698:INFO:                umap: Not installed
2026-02-08 20:33:59,698:INFO:     ydata_profiling: Not installed
2026-02-08 20:33:59,698:INFO:  explainerdashboard: Not installed
2026-02-08 20:33:59,698:INFO:             autoviz: Not installed
2026-02-08 20:33:59,698:INFO:           fairlearn: Not installed
2026-02-08 20:33:59,698:INFO:          deepchecks: Not installed
2026-02-08 20:33:59,698:INFO:             xgboost: Not installed
2026-02-08 20:33:59,698:INFO:            catboost: Not installed
2026-02-08 20:33:59,698:INFO:              kmodes: Not installed
2026-02-08 20:33:59,698:INFO:             mlxtend: Not installed
2026-02-08 20:33:59,698:INFO:       statsforecast: Not installed
2026-02-08 20:33:59,698:INFO:        tune_sklearn: Not installed
2026-02-08 20:33:59,698:INFO:                 ray: Not installed
2026-02-08 20:33:59,698:INFO:            hyperopt: Not installed
2026-02-08 20:33:59,698:INFO:              optuna: Not installed
2026-02-08 20:33:59,698:INFO:               skopt: Not installed
2026-02-08 20:33:59,698:INFO:              mlflow: 3.9.0
2026-02-08 20:33:59,698:INFO:              gradio: Not installed
2026-02-08 20:33:59,698:INFO:             fastapi: 0.128.5
2026-02-08 20:33:59,698:INFO:             uvicorn: 0.40.0
2026-02-08 20:33:59,698:INFO:              m2cgen: Not installed
2026-02-08 20:33:59,698:INFO:           evidently: Not installed
2026-02-08 20:33:59,698:INFO:               fugue: Not installed
2026-02-08 20:33:59,698:INFO:           streamlit: Not installed
2026-02-08 20:33:59,699:INFO:             prophet: Not installed
2026-02-08 20:33:59,699:INFO:None
2026-02-08 20:33:59,699:INFO:Set up data.
2026-02-08 20:33:59,706:INFO:Set up folding strategy.
2026-02-08 20:33:59,706:INFO:Set up train/test split.
2026-02-08 20:33:59,713:INFO:Set up index.
2026-02-08 20:33:59,714:INFO:Assigning column types.
2026-02-08 20:33:59,718:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-08 20:33:59,752:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-08 20:33:59,752:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-08 20:33:59,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-08 20:33:59,790:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-08 20:33:59,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,803:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-08 20:33:59,825:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-08 20:33:59,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,860:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-08 20:33:59,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,873:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-02-08 20:33:59,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:33:59,948:INFO:Preparing preprocessing pipeline...
2026-02-08 20:33:59,950:INFO:Set up simple imputation.
2026-02-08 20:33:59,962:INFO:Finished creating preprocessing pipeline.
2026-02-08 20:33:59,963:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['N', 'P', 'K', 'temperature', 'ph',
                                             'humidity_log', 'rainfall_log'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2026-02-08 20:33:59,963:INFO:Creating final display dataframe.
2026-02-08 20:33:59,993:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type        Multiclass
3           Original data shape         (2200, 8)
4        Transformed data shape         (2200, 8)
5   Transformed train set shape         (1540, 8)
6    Transformed test set shape          (660, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              eefe
2026-02-08 20:34:00,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:34:00,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:34:00,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:34:00,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-08 20:34:00,095:INFO:setup() successfully completed in 0.41s...............
2026-02-08 20:34:00,124:INFO:Initializing compare_models()
2026-02-08 20:34:00,124:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-02-08 20:34:00,125:INFO:Checking exceptions
2026-02-08 20:34:00,129:INFO:Preparing display monitor
2026-02-08 20:34:00,145:INFO:Initializing Logistic Regression
2026-02-08 20:34:00,145:INFO:Total runtime is 2.9166539510091144e-06 minutes
2026-02-08 20:34:00,149:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:00,149:INFO:Initializing create_model()
2026-02-08 20:34:00,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:00,150:INFO:Checking exceptions
2026-02-08 20:34:00,150:INFO:Importing libraries
2026-02-08 20:34:00,150:INFO:Copying training dataset
2026-02-08 20:34:00,156:INFO:Defining folds
2026-02-08 20:34:00,157:INFO:Declaring metric variables
2026-02-08 20:34:00,161:INFO:Importing untrained model
2026-02-08 20:34:00,167:INFO:Logistic Regression Imported successfully
2026-02-08 20:34:00,176:INFO:Starting cross validation
2026-02-08 20:34:00,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:04,326:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:04,326:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:04,326:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:04,326:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:04,326:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:04,326:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:04,326:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:04,326:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:04,326:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:04,327:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:04,736:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:04,736:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:04,738:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:04,738:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:04,738:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:04,740:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:04,741:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:04,742:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:04,743:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:04,744:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:04,799:INFO:Calculating mean and std
2026-02-08 20:34:04,820:INFO:Creating metrics dataframe
2026-02-08 20:34:04,843:INFO:Uploading results into container
2026-02-08 20:34:04,846:INFO:Uploading model into container now
2026-02-08 20:34:04,852:INFO:_master_model_container: 1
2026-02-08 20:34:04,853:INFO:_display_container: 2
2026-02-08 20:34:04,857:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-02-08 20:34:04,857:INFO:create_model() successfully completed......................................
2026-02-08 20:34:05,186:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:05,186:INFO:Creating metrics dataframe
2026-02-08 20:34:05,191:INFO:Initializing K Neighbors Classifier
2026-02-08 20:34:05,191:INFO:Total runtime is 0.08411342700322469 minutes
2026-02-08 20:34:05,194:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:05,194:INFO:Initializing create_model()
2026-02-08 20:34:05,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:05,195:INFO:Checking exceptions
2026-02-08 20:34:05,195:INFO:Importing libraries
2026-02-08 20:34:05,195:INFO:Copying training dataset
2026-02-08 20:34:05,200:INFO:Defining folds
2026-02-08 20:34:05,200:INFO:Declaring metric variables
2026-02-08 20:34:05,202:INFO:Importing untrained model
2026-02-08 20:34:05,205:INFO:K Neighbors Classifier Imported successfully
2026-02-08 20:34:05,211:INFO:Starting cross validation
2026-02-08 20:34:05,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:06,281:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:06,361:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:34:06,492:INFO:Calculating mean and std
2026-02-08 20:34:06,493:INFO:Creating metrics dataframe
2026-02-08 20:34:06,495:INFO:Uploading results into container
2026-02-08 20:34:06,496:INFO:Uploading model into container now
2026-02-08 20:34:06,496:INFO:_master_model_container: 2
2026-02-08 20:34:06,497:INFO:_display_container: 2
2026-02-08 20:34:06,497:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2026-02-08 20:34:06,497:INFO:create_model() successfully completed......................................
2026-02-08 20:34:06,663:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:06,663:INFO:Creating metrics dataframe
2026-02-08 20:34:06,667:INFO:Initializing Naive Bayes
2026-02-08 20:34:06,667:INFO:Total runtime is 0.10871126254399617 minutes
2026-02-08 20:34:06,670:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:06,670:INFO:Initializing create_model()
2026-02-08 20:34:06,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:06,670:INFO:Checking exceptions
2026-02-08 20:34:06,670:INFO:Importing libraries
2026-02-08 20:34:06,670:INFO:Copying training dataset
2026-02-08 20:34:06,674:INFO:Defining folds
2026-02-08 20:34:06,674:INFO:Declaring metric variables
2026-02-08 20:34:06,676:INFO:Importing untrained model
2026-02-08 20:34:06,678:INFO:Naive Bayes Imported successfully
2026-02-08 20:34:06,682:INFO:Starting cross validation
2026-02-08 20:34:06,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:06,768:INFO:Calculating mean and std
2026-02-08 20:34:06,769:INFO:Creating metrics dataframe
2026-02-08 20:34:06,771:INFO:Uploading results into container
2026-02-08 20:34:06,772:INFO:Uploading model into container now
2026-02-08 20:34:06,772:INFO:_master_model_container: 3
2026-02-08 20:34:06,772:INFO:_display_container: 2
2026-02-08 20:34:06,772:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 20:34:06,773:INFO:create_model() successfully completed......................................
2026-02-08 20:34:06,939:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:06,939:INFO:Creating metrics dataframe
2026-02-08 20:34:06,943:INFO:Initializing Decision Tree Classifier
2026-02-08 20:34:06,943:INFO:Total runtime is 0.11331293980280557 minutes
2026-02-08 20:34:06,945:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:06,945:INFO:Initializing create_model()
2026-02-08 20:34:06,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:06,945:INFO:Checking exceptions
2026-02-08 20:34:06,945:INFO:Importing libraries
2026-02-08 20:34:06,945:INFO:Copying training dataset
2026-02-08 20:34:06,948:INFO:Defining folds
2026-02-08 20:34:06,948:INFO:Declaring metric variables
2026-02-08 20:34:06,950:INFO:Importing untrained model
2026-02-08 20:34:06,952:INFO:Decision Tree Classifier Imported successfully
2026-02-08 20:34:06,956:INFO:Starting cross validation
2026-02-08 20:34:06,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:07,034:INFO:Calculating mean and std
2026-02-08 20:34:07,035:INFO:Creating metrics dataframe
2026-02-08 20:34:07,037:INFO:Uploading results into container
2026-02-08 20:34:07,037:INFO:Uploading model into container now
2026-02-08 20:34:07,037:INFO:_master_model_container: 4
2026-02-08 20:34:07,038:INFO:_display_container: 2
2026-02-08 20:34:07,038:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2026-02-08 20:34:07,038:INFO:create_model() successfully completed......................................
2026-02-08 20:34:07,194:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:07,194:INFO:Creating metrics dataframe
2026-02-08 20:34:07,199:INFO:Initializing SVM - Linear Kernel
2026-02-08 20:34:07,199:INFO:Total runtime is 0.11757076183954873 minutes
2026-02-08 20:34:07,200:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:07,201:INFO:Initializing create_model()
2026-02-08 20:34:07,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:07,201:INFO:Checking exceptions
2026-02-08 20:34:07,201:INFO:Importing libraries
2026-02-08 20:34:07,201:INFO:Copying training dataset
2026-02-08 20:34:07,203:INFO:Defining folds
2026-02-08 20:34:07,203:INFO:Declaring metric variables
2026-02-08 20:34:07,205:INFO:Importing untrained model
2026-02-08 20:34:07,207:INFO:SVM - Linear Kernel Imported successfully
2026-02-08 20:34:07,212:INFO:Starting cross validation
2026-02-08 20:34:07,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:07,291:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,294:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,303:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,314:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,317:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,320:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,326:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,327:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,332:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,332:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,344:INFO:Calculating mean and std
2026-02-08 20:34:07,345:INFO:Creating metrics dataframe
2026-02-08 20:34:07,347:INFO:Uploading results into container
2026-02-08 20:34:07,347:INFO:Uploading model into container now
2026-02-08 20:34:07,347:INFO:_master_model_container: 5
2026-02-08 20:34:07,348:INFO:_display_container: 2
2026-02-08 20:34:07,348:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2026-02-08 20:34:07,348:INFO:create_model() successfully completed......................................
2026-02-08 20:34:07,503:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:07,503:INFO:Creating metrics dataframe
2026-02-08 20:34:07,508:INFO:Initializing Ridge Classifier
2026-02-08 20:34:07,508:INFO:Total runtime is 0.12271732886632282 minutes
2026-02-08 20:34:07,509:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:07,510:INFO:Initializing create_model()
2026-02-08 20:34:07,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:07,510:INFO:Checking exceptions
2026-02-08 20:34:07,510:INFO:Importing libraries
2026-02-08 20:34:07,510:INFO:Copying training dataset
2026-02-08 20:34:07,512:INFO:Defining folds
2026-02-08 20:34:07,512:INFO:Declaring metric variables
2026-02-08 20:34:07,513:INFO:Importing untrained model
2026-02-08 20:34:07,515:INFO:Ridge Classifier Imported successfully
2026-02-08 20:34:07,517:INFO:Starting cross validation
2026-02-08 20:34:07,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:07,549:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,549:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,552:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,553:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,554:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,559:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:07,559:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,559:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:07,561:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,561:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,562:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:07,562:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:07,563:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,563:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:07,564:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:07,570:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:07,570:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:07,570:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:07,572:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:07,574:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:07,595:INFO:Calculating mean and std
2026-02-08 20:34:07,596:INFO:Creating metrics dataframe
2026-02-08 20:34:07,598:INFO:Uploading results into container
2026-02-08 20:34:07,599:INFO:Uploading model into container now
2026-02-08 20:34:07,599:INFO:_master_model_container: 6
2026-02-08 20:34:07,600:INFO:_display_container: 2
2026-02-08 20:34:07,600:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2026-02-08 20:34:07,600:INFO:create_model() successfully completed......................................
2026-02-08 20:34:07,763:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:07,763:INFO:Creating metrics dataframe
2026-02-08 20:34:07,770:INFO:Initializing Random Forest Classifier
2026-02-08 20:34:07,770:INFO:Total runtime is 0.1270916144053141 minutes
2026-02-08 20:34:07,773:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:07,773:INFO:Initializing create_model()
2026-02-08 20:34:07,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:07,773:INFO:Checking exceptions
2026-02-08 20:34:07,773:INFO:Importing libraries
2026-02-08 20:34:07,773:INFO:Copying training dataset
2026-02-08 20:34:07,777:INFO:Defining folds
2026-02-08 20:34:07,778:INFO:Declaring metric variables
2026-02-08 20:34:07,780:INFO:Importing untrained model
2026-02-08 20:34:07,783:INFO:Random Forest Classifier Imported successfully
2026-02-08 20:34:07,788:INFO:Starting cross validation
2026-02-08 20:34:07,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:08,573:INFO:Calculating mean and std
2026-02-08 20:34:08,575:INFO:Creating metrics dataframe
2026-02-08 20:34:08,576:INFO:Uploading results into container
2026-02-08 20:34:08,576:INFO:Uploading model into container now
2026-02-08 20:34:08,576:INFO:_master_model_container: 7
2026-02-08 20:34:08,576:INFO:_display_container: 2
2026-02-08 20:34:08,576:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2026-02-08 20:34:08,576:INFO:create_model() successfully completed......................................
2026-02-08 20:34:08,740:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:08,741:INFO:Creating metrics dataframe
2026-02-08 20:34:08,745:INFO:Initializing Quadratic Discriminant Analysis
2026-02-08 20:34:08,745:INFO:Total runtime is 0.14334030548731483 minutes
2026-02-08 20:34:08,747:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:08,747:INFO:Initializing create_model()
2026-02-08 20:34:08,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:08,747:INFO:Checking exceptions
2026-02-08 20:34:08,747:INFO:Importing libraries
2026-02-08 20:34:08,747:INFO:Copying training dataset
2026-02-08 20:34:08,749:INFO:Defining folds
2026-02-08 20:34:08,749:INFO:Declaring metric variables
2026-02-08 20:34:08,751:INFO:Importing untrained model
2026-02-08 20:34:08,753:INFO:Quadratic Discriminant Analysis Imported successfully
2026-02-08 20:34:08,757:INFO:Starting cross validation
2026-02-08 20:34:08,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:08,791:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:08,796:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:08,796:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:08,798:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:08,798:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:08,802:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:08,802:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:08,804:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:08,807:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:08,811:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:08,825:INFO:Calculating mean and std
2026-02-08 20:34:08,826:INFO:Creating metrics dataframe
2026-02-08 20:34:08,828:INFO:Uploading results into container
2026-02-08 20:34:08,828:INFO:Uploading model into container now
2026-02-08 20:34:08,829:INFO:_master_model_container: 8
2026-02-08 20:34:08,829:INFO:_display_container: 2
2026-02-08 20:34:08,829:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2026-02-08 20:34:08,829:INFO:create_model() successfully completed......................................
2026-02-08 20:34:08,989:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:08,990:INFO:Creating metrics dataframe
2026-02-08 20:34:08,994:INFO:Initializing Ada Boost Classifier
2026-02-08 20:34:08,994:INFO:Total runtime is 0.1474968393643697 minutes
2026-02-08 20:34:08,996:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:08,996:INFO:Initializing create_model()
2026-02-08 20:34:08,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:08,996:INFO:Checking exceptions
2026-02-08 20:34:08,996:INFO:Importing libraries
2026-02-08 20:34:08,996:INFO:Copying training dataset
2026-02-08 20:34:08,998:INFO:Defining folds
2026-02-08 20:34:08,998:INFO:Declaring metric variables
2026-02-08 20:34:09,000:INFO:Importing untrained model
2026-02-08 20:34:09,004:INFO:Ada Boost Classifier Imported successfully
2026-02-08 20:34:09,009:INFO:Starting cross validation
2026-02-08 20:34:09,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:09,030:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:34:09,033:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:34:09,034:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:34:09,035:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:34:09,036:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:34:09,037:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:34:09,037:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:34:09,038:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:34:09,039:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:34:09,041:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 20:34:09,270:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:09,276:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:09,277:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:09,284:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:09,308:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:09,313:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:09,317:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:09,317:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:09,320:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:09,321:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:09,322:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:09,323:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:09,327:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:09,328:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:09,329:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:09,330:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:09,334:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:09,334:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:09,339:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:09,342:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:34:09,354:INFO:Calculating mean and std
2026-02-08 20:34:09,354:INFO:Creating metrics dataframe
2026-02-08 20:34:09,356:INFO:Uploading results into container
2026-02-08 20:34:09,357:INFO:Uploading model into container now
2026-02-08 20:34:09,357:INFO:_master_model_container: 9
2026-02-08 20:34:09,357:INFO:_display_container: 2
2026-02-08 20:34:09,358:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2026-02-08 20:34:09,358:INFO:create_model() successfully completed......................................
2026-02-08 20:34:09,514:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:09,514:INFO:Creating metrics dataframe
2026-02-08 20:34:09,519:INFO:Initializing Gradient Boosting Classifier
2026-02-08 20:34:09,519:INFO:Total runtime is 0.15624508062998452 minutes
2026-02-08 20:34:09,521:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:09,521:INFO:Initializing create_model()
2026-02-08 20:34:09,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:09,521:INFO:Checking exceptions
2026-02-08 20:34:09,521:INFO:Importing libraries
2026-02-08 20:34:09,521:INFO:Copying training dataset
2026-02-08 20:34:09,525:INFO:Defining folds
2026-02-08 20:34:09,525:INFO:Declaring metric variables
2026-02-08 20:34:09,526:INFO:Importing untrained model
2026-02-08 20:34:09,528:INFO:Gradient Boosting Classifier Imported successfully
2026-02-08 20:34:09,531:INFO:Starting cross validation
2026-02-08 20:34:09,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:21,031:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:21,073:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:21,331:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:21,568:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:21,623:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:21,669:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:21,686:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:21,709:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:21,716:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:21,747:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:21,759:INFO:Calculating mean and std
2026-02-08 20:34:21,760:INFO:Creating metrics dataframe
2026-02-08 20:34:21,762:INFO:Uploading results into container
2026-02-08 20:34:21,762:INFO:Uploading model into container now
2026-02-08 20:34:21,763:INFO:_master_model_container: 10
2026-02-08 20:34:21,763:INFO:_display_container: 2
2026-02-08 20:34:21,763:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2026-02-08 20:34:21,763:INFO:create_model() successfully completed......................................
2026-02-08 20:34:21,998:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:21,998:INFO:Creating metrics dataframe
2026-02-08 20:34:22,003:INFO:Initializing Linear Discriminant Analysis
2026-02-08 20:34:22,003:INFO:Total runtime is 0.3643059929211934 minutes
2026-02-08 20:34:22,005:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:22,005:INFO:Initializing create_model()
2026-02-08 20:34:22,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:22,005:INFO:Checking exceptions
2026-02-08 20:34:22,005:INFO:Importing libraries
2026-02-08 20:34:22,005:INFO:Copying training dataset
2026-02-08 20:34:22,009:INFO:Defining folds
2026-02-08 20:34:22,010:INFO:Declaring metric variables
2026-02-08 20:34:22,012:INFO:Importing untrained model
2026-02-08 20:34:22,015:INFO:Linear Discriminant Analysis Imported successfully
2026-02-08 20:34:22,021:INFO:Starting cross validation
2026-02-08 20:34:22,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:22,070:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:22,071:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:22,076:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:22,081:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:22,081:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:22,083:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:22,085:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:22,094:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:22,094:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:22,101:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 20:34:22,108:INFO:Calculating mean and std
2026-02-08 20:34:22,109:INFO:Creating metrics dataframe
2026-02-08 20:34:22,111:INFO:Uploading results into container
2026-02-08 20:34:22,111:INFO:Uploading model into container now
2026-02-08 20:34:22,111:INFO:_master_model_container: 11
2026-02-08 20:34:22,112:INFO:_display_container: 2
2026-02-08 20:34:22,112:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2026-02-08 20:34:22,112:INFO:create_model() successfully completed......................................
2026-02-08 20:34:22,282:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:22,282:INFO:Creating metrics dataframe
2026-02-08 20:34:22,287:INFO:Initializing Extra Trees Classifier
2026-02-08 20:34:22,287:INFO:Total runtime is 0.3690357446670532 minutes
2026-02-08 20:34:22,290:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:22,290:INFO:Initializing create_model()
2026-02-08 20:34:22,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:22,290:INFO:Checking exceptions
2026-02-08 20:34:22,290:INFO:Importing libraries
2026-02-08 20:34:22,290:INFO:Copying training dataset
2026-02-08 20:34:22,292:INFO:Defining folds
2026-02-08 20:34:22,292:INFO:Declaring metric variables
2026-02-08 20:34:22,294:INFO:Importing untrained model
2026-02-08 20:34:22,296:INFO:Extra Trees Classifier Imported successfully
2026-02-08 20:34:22,299:INFO:Starting cross validation
2026-02-08 20:34:22,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:34:22,928:INFO:Calculating mean and std
2026-02-08 20:34:22,929:INFO:Creating metrics dataframe
2026-02-08 20:34:22,930:INFO:Uploading results into container
2026-02-08 20:34:22,931:INFO:Uploading model into container now
2026-02-08 20:34:22,931:INFO:_master_model_container: 12
2026-02-08 20:34:22,931:INFO:_display_container: 2
2026-02-08 20:34:22,931:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2026-02-08 20:34:22,931:INFO:create_model() successfully completed......................................
2026-02-08 20:34:23,091:INFO:SubProcess create_model() end ==================================
2026-02-08 20:34:23,091:INFO:Creating metrics dataframe
2026-02-08 20:34:23,096:INFO:Initializing Light Gradient Boosting Machine
2026-02-08 20:34:23,097:INFO:Total runtime is 0.38253145217895507 minutes
2026-02-08 20:34:23,098:INFO:SubProcess create_model() called ==================================
2026-02-08 20:34:23,098:INFO:Initializing create_model()
2026-02-08 20:34:23,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:34:23,099:INFO:Checking exceptions
2026-02-08 20:34:23,099:INFO:Importing libraries
2026-02-08 20:34:23,099:INFO:Copying training dataset
2026-02-08 20:34:23,101:INFO:Defining folds
2026-02-08 20:34:23,101:INFO:Declaring metric variables
2026-02-08 20:34:23,102:INFO:Importing untrained model
2026-02-08 20:34:23,105:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-08 20:34:23,111:INFO:Starting cross validation
2026-02-08 20:34:23,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:35:10,161:INFO:Calculating mean and std
2026-02-08 20:35:10,162:INFO:Creating metrics dataframe
2026-02-08 20:35:10,165:INFO:Uploading results into container
2026-02-08 20:35:10,165:INFO:Uploading model into container now
2026-02-08 20:35:10,166:INFO:_master_model_container: 13
2026-02-08 20:35:10,166:INFO:_display_container: 2
2026-02-08 20:35:10,167:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-02-08 20:35:10,167:INFO:create_model() successfully completed......................................
2026-02-08 20:35:10,368:INFO:SubProcess create_model() end ==================================
2026-02-08 20:35:10,368:INFO:Creating metrics dataframe
2026-02-08 20:35:10,377:INFO:Initializing Dummy Classifier
2026-02-08 20:35:10,377:INFO:Total runtime is 1.170540487766266 minutes
2026-02-08 20:35:10,381:INFO:SubProcess create_model() called ==================================
2026-02-08 20:35:10,381:INFO:Initializing create_model()
2026-02-08 20:35:10,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e94de50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:35:10,381:INFO:Checking exceptions
2026-02-08 20:35:10,381:INFO:Importing libraries
2026-02-08 20:35:10,381:INFO:Copying training dataset
2026-02-08 20:35:10,386:INFO:Defining folds
2026-02-08 20:35:10,387:INFO:Declaring metric variables
2026-02-08 20:35:10,390:INFO:Importing untrained model
2026-02-08 20:35:10,395:INFO:Dummy Classifier Imported successfully
2026-02-08 20:35:10,400:INFO:Starting cross validation
2026-02-08 20:35:10,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:35:10,445:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:35:10,457:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:35:10,460:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:35:10,464:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:35:10,465:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:35:10,465:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:35:10,467:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:35:10,471:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:35:10,526:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:35:10,553:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 20:35:10,569:INFO:Calculating mean and std
2026-02-08 20:35:10,570:INFO:Creating metrics dataframe
2026-02-08 20:35:10,572:INFO:Uploading results into container
2026-02-08 20:35:10,573:INFO:Uploading model into container now
2026-02-08 20:35:10,573:INFO:_master_model_container: 14
2026-02-08 20:35:10,573:INFO:_display_container: 2
2026-02-08 20:35:10,574:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2026-02-08 20:35:10,574:INFO:create_model() successfully completed......................................
2026-02-08 20:35:10,757:INFO:SubProcess create_model() end ==================================
2026-02-08 20:35:10,757:INFO:Creating metrics dataframe
2026-02-08 20:35:10,768:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2026-02-08 20:35:10,774:INFO:Initializing create_model()
2026-02-08 20:35:10,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:35:10,775:INFO:Checking exceptions
2026-02-08 20:35:10,777:INFO:Importing libraries
2026-02-08 20:35:10,777:INFO:Copying training dataset
2026-02-08 20:35:10,780:INFO:Defining folds
2026-02-08 20:35:10,780:INFO:Declaring metric variables
2026-02-08 20:35:10,780:INFO:Importing untrained model
2026-02-08 20:35:10,780:INFO:Declaring custom model
2026-02-08 20:35:10,780:INFO:Naive Bayes Imported successfully
2026-02-08 20:35:10,781:INFO:Cross validation set to False
2026-02-08 20:35:10,781:INFO:Fitting Model
2026-02-08 20:35:10,792:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 20:35:10,792:INFO:create_model() successfully completed......................................
2026-02-08 20:35:10,981:INFO:_master_model_container: 14
2026-02-08 20:35:10,981:INFO:_display_container: 2
2026-02-08 20:35:10,981:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 20:35:10,981:INFO:compare_models() successfully completed......................................
2026-02-08 20:35:11,006:INFO:Initializing predict_model()
2026-02-08 20:35:11,006:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7e79343db2e0>)
2026-02-08 20:35:11,006:INFO:Checking exceptions
2026-02-08 20:35:11,006:INFO:Preloading libraries
2026-02-08 20:35:11,008:INFO:Set up data.
2026-02-08 20:35:11,014:INFO:Set up index.
2026-02-08 20:35:11,340:INFO:Initializing tune_model()
2026-02-08 20:35:11,340:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=20, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-02-08 20:35:11,340:INFO:Checking exceptions
2026-02-08 20:35:11,363:INFO:Copying training dataset
2026-02-08 20:35:11,366:INFO:Checking base model
2026-02-08 20:35:11,366:INFO:Base model : Naive Bayes
2026-02-08 20:35:11,370:INFO:Declaring metric variables
2026-02-08 20:35:11,373:INFO:Defining Hyperparameters
2026-02-08 20:35:11,589:INFO:Tuning with n_jobs=-1
2026-02-08 20:35:11,590:INFO:Initializing RandomizedSearchCV
2026-02-08 20:35:12,596:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2026-02-08 20:35:12,598:INFO:Hyperparameter search completed
2026-02-08 20:35:12,598:INFO:SubProcess create_model() called ==================================
2026-02-08 20:35:12,599:INFO:Initializing create_model()
2026-02-08 20:35:12,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78ed3e0ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2026-02-08 20:35:12,600:INFO:Checking exceptions
2026-02-08 20:35:12,600:INFO:Importing libraries
2026-02-08 20:35:12,600:INFO:Copying training dataset
2026-02-08 20:35:12,613:INFO:Defining folds
2026-02-08 20:35:12,614:INFO:Declaring metric variables
2026-02-08 20:35:12,622:INFO:Importing untrained model
2026-02-08 20:35:12,622:INFO:Declaring custom model
2026-02-08 20:35:12,630:INFO:Naive Bayes Imported successfully
2026-02-08 20:35:12,645:INFO:Starting cross validation
2026-02-08 20:35:12,647:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:35:12,835:INFO:Calculating mean and std
2026-02-08 20:35:12,837:INFO:Creating metrics dataframe
2026-02-08 20:35:12,844:INFO:Finalizing model
2026-02-08 20:35:12,871:INFO:Uploading results into container
2026-02-08 20:35:12,872:INFO:Uploading model into container now
2026-02-08 20:35:12,873:INFO:_master_model_container: 15
2026-02-08 20:35:12,874:INFO:_display_container: 4
2026-02-08 20:35:12,874:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 20:35:12,874:INFO:create_model() successfully completed......................................
2026-02-08 20:35:13,154:INFO:SubProcess create_model() end ==================================
2026-02-08 20:35:13,154:INFO:choose_better activated
2026-02-08 20:35:13,157:INFO:SubProcess create_model() called ==================================
2026-02-08 20:35:13,158:INFO:Initializing create_model()
2026-02-08 20:35:13,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:35:13,158:INFO:Checking exceptions
2026-02-08 20:35:13,160:INFO:Importing libraries
2026-02-08 20:35:13,160:INFO:Copying training dataset
2026-02-08 20:35:13,164:INFO:Defining folds
2026-02-08 20:35:13,164:INFO:Declaring metric variables
2026-02-08 20:35:13,164:INFO:Importing untrained model
2026-02-08 20:35:13,164:INFO:Declaring custom model
2026-02-08 20:35:13,165:INFO:Naive Bayes Imported successfully
2026-02-08 20:35:13,165:INFO:Starting cross validation
2026-02-08 20:35:13,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:35:13,297:INFO:Calculating mean and std
2026-02-08 20:35:13,298:INFO:Creating metrics dataframe
2026-02-08 20:35:13,300:INFO:Finalizing model
2026-02-08 20:35:13,316:INFO:Uploading results into container
2026-02-08 20:35:13,317:INFO:Uploading model into container now
2026-02-08 20:35:13,318:INFO:_master_model_container: 16
2026-02-08 20:35:13,318:INFO:_display_container: 5
2026-02-08 20:35:13,318:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 20:35:13,318:INFO:create_model() successfully completed......................................
2026-02-08 20:35:13,573:INFO:SubProcess create_model() end ==================================
2026-02-08 20:35:13,574:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for F1 is 0.9948
2026-02-08 20:35:13,574:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for F1 is 0.9948
2026-02-08 20:35:13,574:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2026-02-08 20:35:13,574:INFO:choose_better completed
2026-02-08 20:35:13,574:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-02-08 20:35:13,584:INFO:_master_model_container: 16
2026-02-08 20:35:13,585:INFO:_display_container: 4
2026-02-08 20:35:13,585:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 20:35:13,585:INFO:tune_model() successfully completed......................................
2026-02-08 20:56:53,836:INFO:Initializing tune_model()
2026-02-08 20:56:53,836:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=50, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-02-08 20:56:53,837:INFO:Checking exceptions
2026-02-08 20:56:53,849:INFO:Copying training dataset
2026-02-08 20:56:53,850:INFO:Checking base model
2026-02-08 20:56:53,851:INFO:Base model : Naive Bayes
2026-02-08 20:56:53,852:INFO:Declaring metric variables
2026-02-08 20:56:53,854:INFO:Defining Hyperparameters
2026-02-08 20:56:53,854:INFO:50 is bigger than total combinations 28, setting search algorithm to grid
2026-02-08 20:56:54,129:INFO:Tuning with n_jobs=-1
2026-02-08 20:56:54,129:INFO:Initializing GridSearchCV
2026-02-08 20:57:00,625:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,625:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,626:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,625:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,626:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,626:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,626:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,625:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,626:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,627:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,627:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:00,627:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 20:57:01,995:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2026-02-08 20:57:02,003:INFO:Hyperparameter search completed
2026-02-08 20:57:02,011:INFO:SubProcess create_model() called ==================================
2026-02-08 20:57:02,012:INFO:Initializing create_model()
2026-02-08 20:57:02,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e795e836610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2026-02-08 20:57:02,012:INFO:Checking exceptions
2026-02-08 20:57:02,012:INFO:Importing libraries
2026-02-08 20:57:02,012:INFO:Copying training dataset
2026-02-08 20:57:02,022:INFO:Defining folds
2026-02-08 20:57:02,022:INFO:Declaring metric variables
2026-02-08 20:57:02,028:INFO:Importing untrained model
2026-02-08 20:57:02,028:INFO:Declaring custom model
2026-02-08 20:57:02,031:INFO:Naive Bayes Imported successfully
2026-02-08 20:57:02,037:INFO:Starting cross validation
2026-02-08 20:57:02,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:57:02,164:INFO:Calculating mean and std
2026-02-08 20:57:02,166:INFO:Creating metrics dataframe
2026-02-08 20:57:02,171:INFO:Finalizing model
2026-02-08 20:57:02,190:INFO:Uploading results into container
2026-02-08 20:57:02,191:INFO:Uploading model into container now
2026-02-08 20:57:02,192:INFO:_master_model_container: 17
2026-02-08 20:57:02,192:INFO:_display_container: 5
2026-02-08 20:57:02,192:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 20:57:02,192:INFO:create_model() successfully completed......................................
2026-02-08 20:57:02,477:INFO:SubProcess create_model() end ==================================
2026-02-08 20:57:02,477:INFO:choose_better activated
2026-02-08 20:57:02,481:INFO:SubProcess create_model() called ==================================
2026-02-08 20:57:02,482:INFO:Initializing create_model()
2026-02-08 20:57:02,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 20:57:02,483:INFO:Checking exceptions
2026-02-08 20:57:02,486:INFO:Importing libraries
2026-02-08 20:57:02,486:INFO:Copying training dataset
2026-02-08 20:57:02,496:INFO:Defining folds
2026-02-08 20:57:02,496:INFO:Declaring metric variables
2026-02-08 20:57:02,497:INFO:Importing untrained model
2026-02-08 20:57:02,497:INFO:Declaring custom model
2026-02-08 20:57:02,497:INFO:Naive Bayes Imported successfully
2026-02-08 20:57:02,498:INFO:Starting cross validation
2026-02-08 20:57:02,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 20:57:02,628:INFO:Calculating mean and std
2026-02-08 20:57:02,629:INFO:Creating metrics dataframe
2026-02-08 20:57:02,631:INFO:Finalizing model
2026-02-08 20:57:02,642:INFO:Uploading results into container
2026-02-08 20:57:02,643:INFO:Uploading model into container now
2026-02-08 20:57:02,643:INFO:_master_model_container: 18
2026-02-08 20:57:02,643:INFO:_display_container: 6
2026-02-08 20:57:02,644:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 20:57:02,644:INFO:create_model() successfully completed......................................
2026-02-08 20:57:02,807:INFO:SubProcess create_model() end ==================================
2026-02-08 20:57:02,807:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for F1 is 0.9948
2026-02-08 20:57:02,807:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for F1 is 0.9948
2026-02-08 20:57:02,808:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2026-02-08 20:57:02,808:INFO:choose_better completed
2026-02-08 20:57:02,808:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-02-08 20:57:02,814:INFO:_master_model_container: 18
2026-02-08 20:57:02,814:INFO:_display_container: 5
2026-02-08 20:57:02,814:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 20:57:02,814:INFO:tune_model() successfully completed......................................
2026-02-08 21:03:55,664:INFO:Initializing evaluate_model()
2026-02-08 21:03:55,664:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-02-08 21:03:55,672:INFO:Initializing plot_model()
2026-02-08 21:03:55,672:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 21:03:55,672:INFO:Checking exceptions
2026-02-08 21:03:55,673:INFO:Preloading libraries
2026-02-08 21:03:55,673:INFO:Copying training dataset
2026-02-08 21:03:55,673:INFO:Plot type: pipeline
2026-02-08 21:03:55,845:INFO:Visual Rendered Successfully
2026-02-08 21:03:56,038:INFO:plot_model() successfully completed......................................
2026-02-08 21:04:44,866:INFO:Initializing evaluate_model()
2026-02-08 21:04:44,866:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-02-08 21:04:44,873:INFO:Initializing plot_model()
2026-02-08 21:04:44,873:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 21:04:44,874:INFO:Checking exceptions
2026-02-08 21:04:44,876:INFO:Preloading libraries
2026-02-08 21:04:44,876:INFO:Copying training dataset
2026-02-08 21:04:44,876:INFO:Plot type: pipeline
2026-02-08 21:04:44,928:INFO:Visual Rendered Successfully
2026-02-08 21:04:45,102:INFO:plot_model() successfully completed......................................
2026-02-08 21:04:46,612:INFO:Initializing plot_model()
2026-02-08 21:04:46,612:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 21:04:46,612:INFO:Checking exceptions
2026-02-08 21:04:51,972:INFO:Initializing plot_model()
2026-02-08 21:04:51,972:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 21:04:51,972:INFO:Checking exceptions
2026-02-08 21:05:18,445:INFO:Initializing compare_models()
2026-02-08 21:05:18,446:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-02-08 21:05:18,446:INFO:Checking exceptions
2026-02-08 21:05:18,448:INFO:Preparing display monitor
2026-02-08 21:05:18,461:INFO:Initializing Logistic Regression
2026-02-08 21:05:18,461:INFO:Total runtime is 1.708666483561198e-06 minutes
2026-02-08 21:05:18,463:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:18,463:INFO:Initializing create_model()
2026-02-08 21:05:18,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:18,464:INFO:Checking exceptions
2026-02-08 21:05:18,464:INFO:Importing libraries
2026-02-08 21:05:18,464:INFO:Copying training dataset
2026-02-08 21:05:18,466:INFO:Defining folds
2026-02-08 21:05:18,466:INFO:Declaring metric variables
2026-02-08 21:05:18,468:INFO:Importing untrained model
2026-02-08 21:05:18,470:INFO:Logistic Regression Imported successfully
2026-02-08 21:05:18,476:INFO:Starting cross validation
2026-02-08 21:05:18,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:21,653:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:21,653:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:21,653:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:21,653:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:21,653:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:21,653:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:21,653:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:21,653:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:21,653:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:21,653:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:21,937:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:21,948:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:21,957:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:21,958:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:21,959:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:21,961:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:21,966:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:21,967:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:21,972:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:21,975:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:22,008:INFO:Calculating mean and std
2026-02-08 21:05:22,013:INFO:Creating metrics dataframe
2026-02-08 21:05:22,026:INFO:Uploading results into container
2026-02-08 21:05:22,028:INFO:Uploading model into container now
2026-02-08 21:05:22,029:INFO:_master_model_container: 19
2026-02-08 21:05:22,030:INFO:_display_container: 6
2026-02-08 21:05:22,031:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-02-08 21:05:22,031:INFO:create_model() successfully completed......................................
2026-02-08 21:05:22,277:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:22,277:INFO:Creating metrics dataframe
2026-02-08 21:05:22,284:INFO:Initializing K Neighbors Classifier
2026-02-08 21:05:22,285:INFO:Total runtime is 0.06372123559316 minutes
2026-02-08 21:05:22,286:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:22,287:INFO:Initializing create_model()
2026-02-08 21:05:22,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:22,287:INFO:Checking exceptions
2026-02-08 21:05:22,287:INFO:Importing libraries
2026-02-08 21:05:22,287:INFO:Copying training dataset
2026-02-08 21:05:22,289:INFO:Defining folds
2026-02-08 21:05:22,289:INFO:Declaring metric variables
2026-02-08 21:05:22,291:INFO:Importing untrained model
2026-02-08 21:05:22,292:INFO:K Neighbors Classifier Imported successfully
2026-02-08 21:05:22,295:INFO:Starting cross validation
2026-02-08 21:05:22,296:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:23,714:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:23,717:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-08 21:05:23,847:INFO:Calculating mean and std
2026-02-08 21:05:23,848:INFO:Creating metrics dataframe
2026-02-08 21:05:23,850:INFO:Uploading results into container
2026-02-08 21:05:23,851:INFO:Uploading model into container now
2026-02-08 21:05:23,851:INFO:_master_model_container: 20
2026-02-08 21:05:23,851:INFO:_display_container: 6
2026-02-08 21:05:23,852:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2026-02-08 21:05:23,852:INFO:create_model() successfully completed......................................
2026-02-08 21:05:24,016:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:24,016:INFO:Creating metrics dataframe
2026-02-08 21:05:24,021:INFO:Initializing Naive Bayes
2026-02-08 21:05:24,022:INFO:Total runtime is 0.09267135063807169 minutes
2026-02-08 21:05:24,023:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:24,024:INFO:Initializing create_model()
2026-02-08 21:05:24,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:24,024:INFO:Checking exceptions
2026-02-08 21:05:24,024:INFO:Importing libraries
2026-02-08 21:05:24,024:INFO:Copying training dataset
2026-02-08 21:05:24,026:INFO:Defining folds
2026-02-08 21:05:24,026:INFO:Declaring metric variables
2026-02-08 21:05:24,028:INFO:Importing untrained model
2026-02-08 21:05:24,030:INFO:Naive Bayes Imported successfully
2026-02-08 21:05:24,034:INFO:Starting cross validation
2026-02-08 21:05:24,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:24,171:INFO:Calculating mean and std
2026-02-08 21:05:24,172:INFO:Creating metrics dataframe
2026-02-08 21:05:24,174:INFO:Uploading results into container
2026-02-08 21:05:24,175:INFO:Uploading model into container now
2026-02-08 21:05:24,175:INFO:_master_model_container: 21
2026-02-08 21:05:24,175:INFO:_display_container: 6
2026-02-08 21:05:24,175:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 21:05:24,175:INFO:create_model() successfully completed......................................
2026-02-08 21:05:24,389:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:24,389:INFO:Creating metrics dataframe
2026-02-08 21:05:24,394:INFO:Initializing Decision Tree Classifier
2026-02-08 21:05:24,394:INFO:Total runtime is 0.09887992938359579 minutes
2026-02-08 21:05:24,397:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:24,397:INFO:Initializing create_model()
2026-02-08 21:05:24,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:24,397:INFO:Checking exceptions
2026-02-08 21:05:24,398:INFO:Importing libraries
2026-02-08 21:05:24,398:INFO:Copying training dataset
2026-02-08 21:05:24,401:INFO:Defining folds
2026-02-08 21:05:24,401:INFO:Declaring metric variables
2026-02-08 21:05:24,404:INFO:Importing untrained model
2026-02-08 21:05:24,406:INFO:Decision Tree Classifier Imported successfully
2026-02-08 21:05:24,411:INFO:Starting cross validation
2026-02-08 21:05:24,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:24,501:INFO:Calculating mean and std
2026-02-08 21:05:24,502:INFO:Creating metrics dataframe
2026-02-08 21:05:24,505:INFO:Uploading results into container
2026-02-08 21:05:24,506:INFO:Uploading model into container now
2026-02-08 21:05:24,506:INFO:_master_model_container: 22
2026-02-08 21:05:24,506:INFO:_display_container: 6
2026-02-08 21:05:24,507:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2026-02-08 21:05:24,507:INFO:create_model() successfully completed......................................
2026-02-08 21:05:24,674:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:24,674:INFO:Creating metrics dataframe
2026-02-08 21:05:24,678:INFO:Initializing SVM - Linear Kernel
2026-02-08 21:05:24,679:INFO:Total runtime is 0.10362151463826498 minutes
2026-02-08 21:05:24,680:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:24,680:INFO:Initializing create_model()
2026-02-08 21:05:24,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:24,680:INFO:Checking exceptions
2026-02-08 21:05:24,680:INFO:Importing libraries
2026-02-08 21:05:24,680:INFO:Copying training dataset
2026-02-08 21:05:24,683:INFO:Defining folds
2026-02-08 21:05:24,683:INFO:Declaring metric variables
2026-02-08 21:05:24,685:INFO:Importing untrained model
2026-02-08 21:05:24,686:INFO:SVM - Linear Kernel Imported successfully
2026-02-08 21:05:24,690:INFO:Starting cross validation
2026-02-08 21:05:24,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:24,778:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:24,779:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:24,797:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:24,800:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:24,801:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:24,804:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:24,808:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:24,812:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:24,817:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:24,824:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:24,851:INFO:Calculating mean and std
2026-02-08 21:05:24,853:INFO:Creating metrics dataframe
2026-02-08 21:05:24,862:INFO:Uploading results into container
2026-02-08 21:05:24,862:INFO:Uploading model into container now
2026-02-08 21:05:24,863:INFO:_master_model_container: 23
2026-02-08 21:05:24,863:INFO:_display_container: 6
2026-02-08 21:05:24,864:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2026-02-08 21:05:24,864:INFO:create_model() successfully completed......................................
2026-02-08 21:05:25,033:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:25,034:INFO:Creating metrics dataframe
2026-02-08 21:05:25,039:INFO:Initializing Ridge Classifier
2026-02-08 21:05:25,039:INFO:Total runtime is 0.10962368647257488 minutes
2026-02-08 21:05:25,040:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:25,040:INFO:Initializing create_model()
2026-02-08 21:05:25,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:25,040:INFO:Checking exceptions
2026-02-08 21:05:25,041:INFO:Importing libraries
2026-02-08 21:05:25,041:INFO:Copying training dataset
2026-02-08 21:05:25,043:INFO:Defining folds
2026-02-08 21:05:25,043:INFO:Declaring metric variables
2026-02-08 21:05:25,045:INFO:Importing untrained model
2026-02-08 21:05:25,047:INFO:Ridge Classifier Imported successfully
2026-02-08 21:05:25,050:INFO:Starting cross validation
2026-02-08 21:05:25,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:25,078:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:25,078:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:25,079:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:25,085:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:25,085:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:25,087:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:25,087:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:25,088:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:25,089:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:25,090:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:25,090:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:25,090:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:25,094:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:25,095:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:25,095:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:25,096:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:25,098:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:25,099:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:25,099:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:25,105:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:25,119:INFO:Calculating mean and std
2026-02-08 21:05:25,120:INFO:Creating metrics dataframe
2026-02-08 21:05:25,122:INFO:Uploading results into container
2026-02-08 21:05:25,123:INFO:Uploading model into container now
2026-02-08 21:05:25,123:INFO:_master_model_container: 24
2026-02-08 21:05:25,123:INFO:_display_container: 6
2026-02-08 21:05:25,123:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2026-02-08 21:05:25,124:INFO:create_model() successfully completed......................................
2026-02-08 21:05:25,286:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:25,286:INFO:Creating metrics dataframe
2026-02-08 21:05:25,291:INFO:Initializing Random Forest Classifier
2026-02-08 21:05:25,291:INFO:Total runtime is 0.11382480065027874 minutes
2026-02-08 21:05:25,292:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:25,293:INFO:Initializing create_model()
2026-02-08 21:05:25,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:25,293:INFO:Checking exceptions
2026-02-08 21:05:25,293:INFO:Importing libraries
2026-02-08 21:05:25,293:INFO:Copying training dataset
2026-02-08 21:05:25,296:INFO:Defining folds
2026-02-08 21:05:25,296:INFO:Declaring metric variables
2026-02-08 21:05:25,298:INFO:Importing untrained model
2026-02-08 21:05:25,300:INFO:Random Forest Classifier Imported successfully
2026-02-08 21:05:25,304:INFO:Starting cross validation
2026-02-08 21:05:25,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:26,200:INFO:Calculating mean and std
2026-02-08 21:05:26,201:INFO:Creating metrics dataframe
2026-02-08 21:05:26,202:INFO:Uploading results into container
2026-02-08 21:05:26,202:INFO:Uploading model into container now
2026-02-08 21:05:26,203:INFO:_master_model_container: 25
2026-02-08 21:05:26,203:INFO:_display_container: 6
2026-02-08 21:05:26,204:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2026-02-08 21:05:26,204:INFO:create_model() successfully completed......................................
2026-02-08 21:05:26,364:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:26,364:INFO:Creating metrics dataframe
2026-02-08 21:05:26,368:INFO:Initializing Quadratic Discriminant Analysis
2026-02-08 21:05:26,368:INFO:Total runtime is 0.13178006807963055 minutes
2026-02-08 21:05:26,370:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:26,370:INFO:Initializing create_model()
2026-02-08 21:05:26,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:26,370:INFO:Checking exceptions
2026-02-08 21:05:26,370:INFO:Importing libraries
2026-02-08 21:05:26,370:INFO:Copying training dataset
2026-02-08 21:05:26,372:INFO:Defining folds
2026-02-08 21:05:26,372:INFO:Declaring metric variables
2026-02-08 21:05:26,374:INFO:Importing untrained model
2026-02-08 21:05:26,376:INFO:Quadratic Discriminant Analysis Imported successfully
2026-02-08 21:05:26,381:INFO:Starting cross validation
2026-02-08 21:05:26,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:26,417:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,419:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,419:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,421:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,423:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,423:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,429:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,429:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,429:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,433:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,459:INFO:Calculating mean and std
2026-02-08 21:05:26,459:INFO:Creating metrics dataframe
2026-02-08 21:05:26,461:INFO:Uploading results into container
2026-02-08 21:05:26,462:INFO:Uploading model into container now
2026-02-08 21:05:26,462:INFO:_master_model_container: 26
2026-02-08 21:05:26,462:INFO:_display_container: 6
2026-02-08 21:05:26,463:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2026-02-08 21:05:26,463:INFO:create_model() successfully completed......................................
2026-02-08 21:05:26,623:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:26,623:INFO:Creating metrics dataframe
2026-02-08 21:05:26,628:INFO:Initializing Ada Boost Classifier
2026-02-08 21:05:26,628:INFO:Total runtime is 0.13610928853352866 minutes
2026-02-08 21:05:26,630:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:26,630:INFO:Initializing create_model()
2026-02-08 21:05:26,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:26,630:INFO:Checking exceptions
2026-02-08 21:05:26,630:INFO:Importing libraries
2026-02-08 21:05:26,630:INFO:Copying training dataset
2026-02-08 21:05:26,632:INFO:Defining folds
2026-02-08 21:05:26,632:INFO:Declaring metric variables
2026-02-08 21:05:26,634:INFO:Importing untrained model
2026-02-08 21:05:26,637:INFO:Ada Boost Classifier Imported successfully
2026-02-08 21:05:26,640:INFO:Starting cross validation
2026-02-08 21:05:26,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:26,658:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 21:05:26,658:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 21:05:26,659:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 21:05:26,661:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 21:05:26,661:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 21:05:26,664:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 21:05:26,664:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 21:05:26,664:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 21:05:26,665:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 21:05:26,669:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-08 21:05:26,947:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,954:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:26,958:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,962:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:26,973:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,974:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,974:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,976:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:26,979:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:26,979:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:26,980:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,985:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:26,989:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,990:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,990:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,993:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:26,993:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:26,995:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:26,995:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:26,998:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:05:27,011:INFO:Calculating mean and std
2026-02-08 21:05:27,012:INFO:Creating metrics dataframe
2026-02-08 21:05:27,013:INFO:Uploading results into container
2026-02-08 21:05:27,014:INFO:Uploading model into container now
2026-02-08 21:05:27,014:INFO:_master_model_container: 27
2026-02-08 21:05:27,014:INFO:_display_container: 6
2026-02-08 21:05:27,015:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2026-02-08 21:05:27,015:INFO:create_model() successfully completed......................................
2026-02-08 21:05:27,179:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:27,179:INFO:Creating metrics dataframe
2026-02-08 21:05:27,184:INFO:Initializing Gradient Boosting Classifier
2026-02-08 21:05:27,184:INFO:Total runtime is 0.14538544813791912 minutes
2026-02-08 21:05:27,187:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:27,187:INFO:Initializing create_model()
2026-02-08 21:05:27,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:27,188:INFO:Checking exceptions
2026-02-08 21:05:27,188:INFO:Importing libraries
2026-02-08 21:05:27,188:INFO:Copying training dataset
2026-02-08 21:05:27,191:INFO:Defining folds
2026-02-08 21:05:27,191:INFO:Declaring metric variables
2026-02-08 21:05:27,192:INFO:Importing untrained model
2026-02-08 21:05:27,194:INFO:Gradient Boosting Classifier Imported successfully
2026-02-08 21:05:27,200:INFO:Starting cross validation
2026-02-08 21:05:27,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:39,179:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:39,487:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:39,665:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:39,697:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:39,745:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:39,758:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:39,796:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:39,823:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:39,865:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:39,873:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:39,891:INFO:Calculating mean and std
2026-02-08 21:05:39,892:INFO:Creating metrics dataframe
2026-02-08 21:05:39,893:INFO:Uploading results into container
2026-02-08 21:05:39,893:INFO:Uploading model into container now
2026-02-08 21:05:39,894:INFO:_master_model_container: 28
2026-02-08 21:05:39,894:INFO:_display_container: 6
2026-02-08 21:05:39,894:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2026-02-08 21:05:39,894:INFO:create_model() successfully completed......................................
2026-02-08 21:05:40,054:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:40,054:INFO:Creating metrics dataframe
2026-02-08 21:05:40,060:INFO:Initializing Linear Discriminant Analysis
2026-02-08 21:05:40,060:INFO:Total runtime is 0.3599731246630351 minutes
2026-02-08 21:05:40,062:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:40,063:INFO:Initializing create_model()
2026-02-08 21:05:40,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:40,063:INFO:Checking exceptions
2026-02-08 21:05:40,063:INFO:Importing libraries
2026-02-08 21:05:40,063:INFO:Copying training dataset
2026-02-08 21:05:40,065:INFO:Defining folds
2026-02-08 21:05:40,065:INFO:Declaring metric variables
2026-02-08 21:05:40,067:INFO:Importing untrained model
2026-02-08 21:05:40,071:INFO:Linear Discriminant Analysis Imported successfully
2026-02-08 21:05:40,075:INFO:Starting cross validation
2026-02-08 21:05:40,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:40,101:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:40,108:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:40,110:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:40,114:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:40,124:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:40,125:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:40,129:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:40,139:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:40,142:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:40,146:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-08 21:05:40,165:INFO:Calculating mean and std
2026-02-08 21:05:40,166:INFO:Creating metrics dataframe
2026-02-08 21:05:40,168:INFO:Uploading results into container
2026-02-08 21:05:40,169:INFO:Uploading model into container now
2026-02-08 21:05:40,169:INFO:_master_model_container: 29
2026-02-08 21:05:40,169:INFO:_display_container: 6
2026-02-08 21:05:40,170:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2026-02-08 21:05:40,170:INFO:create_model() successfully completed......................................
2026-02-08 21:05:40,356:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:40,356:INFO:Creating metrics dataframe
2026-02-08 21:05:40,361:INFO:Initializing Extra Trees Classifier
2026-02-08 21:05:40,361:INFO:Total runtime is 0.3650010188420614 minutes
2026-02-08 21:05:40,363:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:40,363:INFO:Initializing create_model()
2026-02-08 21:05:40,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:40,363:INFO:Checking exceptions
2026-02-08 21:05:40,363:INFO:Importing libraries
2026-02-08 21:05:40,363:INFO:Copying training dataset
2026-02-08 21:05:40,365:INFO:Defining folds
2026-02-08 21:05:40,365:INFO:Declaring metric variables
2026-02-08 21:05:40,367:INFO:Importing untrained model
2026-02-08 21:05:40,369:INFO:Extra Trees Classifier Imported successfully
2026-02-08 21:05:40,374:INFO:Starting cross validation
2026-02-08 21:05:40,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:05:41,037:INFO:Calculating mean and std
2026-02-08 21:05:41,037:INFO:Creating metrics dataframe
2026-02-08 21:05:41,039:INFO:Uploading results into container
2026-02-08 21:05:41,039:INFO:Uploading model into container now
2026-02-08 21:05:41,039:INFO:_master_model_container: 30
2026-02-08 21:05:41,039:INFO:_display_container: 6
2026-02-08 21:05:41,040:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2026-02-08 21:05:41,040:INFO:create_model() successfully completed......................................
2026-02-08 21:05:41,200:INFO:SubProcess create_model() end ==================================
2026-02-08 21:05:41,200:INFO:Creating metrics dataframe
2026-02-08 21:05:41,207:INFO:Initializing Light Gradient Boosting Machine
2026-02-08 21:05:41,207:INFO:Total runtime is 0.37909163236618043 minutes
2026-02-08 21:05:41,209:INFO:SubProcess create_model() called ==================================
2026-02-08 21:05:41,209:INFO:Initializing create_model()
2026-02-08 21:05:41,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:05:41,209:INFO:Checking exceptions
2026-02-08 21:05:41,209:INFO:Importing libraries
2026-02-08 21:05:41,209:INFO:Copying training dataset
2026-02-08 21:05:41,211:INFO:Defining folds
2026-02-08 21:05:41,212:INFO:Declaring metric variables
2026-02-08 21:05:41,213:INFO:Importing untrained model
2026-02-08 21:05:41,215:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-08 21:05:41,223:INFO:Starting cross validation
2026-02-08 21:05:41,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:06:14,988:INFO:Calculating mean and std
2026-02-08 21:06:14,990:INFO:Creating metrics dataframe
2026-02-08 21:06:14,994:INFO:Uploading results into container
2026-02-08 21:06:14,995:INFO:Uploading model into container now
2026-02-08 21:06:14,997:INFO:_master_model_container: 31
2026-02-08 21:06:14,997:INFO:_display_container: 6
2026-02-08 21:06:14,998:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-02-08 21:06:14,998:INFO:create_model() successfully completed......................................
2026-02-08 21:06:15,228:INFO:SubProcess create_model() end ==================================
2026-02-08 21:06:15,228:INFO:Creating metrics dataframe
2026-02-08 21:06:15,237:INFO:Initializing Dummy Classifier
2026-02-08 21:06:15,237:INFO:Total runtime is 0.946265168984731 minutes
2026-02-08 21:06:15,240:INFO:SubProcess create_model() called ==================================
2026-02-08 21:06:15,240:INFO:Initializing create_model()
2026-02-08 21:06:15,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7e78efbef650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:06:15,240:INFO:Checking exceptions
2026-02-08 21:06:15,240:INFO:Importing libraries
2026-02-08 21:06:15,240:INFO:Copying training dataset
2026-02-08 21:06:15,244:INFO:Defining folds
2026-02-08 21:06:15,244:INFO:Declaring metric variables
2026-02-08 21:06:15,247:INFO:Importing untrained model
2026-02-08 21:06:15,249:INFO:Dummy Classifier Imported successfully
2026-02-08 21:06:15,254:INFO:Starting cross validation
2026-02-08 21:06:15,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-08 21:06:15,332:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:06:15,335:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:06:15,335:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:06:15,336:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:06:15,336:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:06:15,341:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:06:15,353:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:06:15,361:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:06:15,360:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:06:15,383:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-08 21:06:15,402:INFO:Calculating mean and std
2026-02-08 21:06:15,404:INFO:Creating metrics dataframe
2026-02-08 21:06:15,407:INFO:Uploading results into container
2026-02-08 21:06:15,408:INFO:Uploading model into container now
2026-02-08 21:06:15,408:INFO:_master_model_container: 32
2026-02-08 21:06:15,408:INFO:_display_container: 6
2026-02-08 21:06:15,409:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2026-02-08 21:06:15,409:INFO:create_model() successfully completed......................................
2026-02-08 21:06:15,611:INFO:SubProcess create_model() end ==================================
2026-02-08 21:06:15,611:INFO:Creating metrics dataframe
2026-02-08 21:06:15,622:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2026-02-08 21:06:15,629:INFO:Initializing create_model()
2026-02-08 21:06:15,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-08 21:06:15,630:INFO:Checking exceptions
2026-02-08 21:06:15,632:INFO:Importing libraries
2026-02-08 21:06:15,632:INFO:Copying training dataset
2026-02-08 21:06:15,634:INFO:Defining folds
2026-02-08 21:06:15,634:INFO:Declaring metric variables
2026-02-08 21:06:15,635:INFO:Importing untrained model
2026-02-08 21:06:15,635:INFO:Declaring custom model
2026-02-08 21:06:15,635:INFO:Naive Bayes Imported successfully
2026-02-08 21:06:15,635:INFO:Cross validation set to False
2026-02-08 21:06:15,635:INFO:Fitting Model
2026-02-08 21:06:15,650:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 21:06:15,650:INFO:create_model() successfully completed......................................
2026-02-08 21:06:15,869:INFO:_master_model_container: 32
2026-02-08 21:06:15,869:INFO:_display_container: 6
2026-02-08 21:06:15,869:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-08 21:06:15,869:INFO:compare_models() successfully completed......................................
2026-02-08 21:59:52,052:INFO:Initializing plot_model()
2026-02-08 21:59:52,053:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 21:59:52,054:INFO:Checking exceptions
2026-02-08 21:59:53,097:INFO:Initializing plot_model()
2026-02-08 21:59:53,098:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 21:59:53,098:INFO:Checking exceptions
2026-02-08 21:59:53,126:INFO:Preloading libraries
2026-02-08 21:59:53,130:INFO:Copying training dataset
2026-02-08 21:59:53,130:INFO:Plot type: pipeline
2026-02-08 21:59:53,434:INFO:Visual Rendered Successfully
2026-02-08 21:59:54,068:INFO:plot_model() successfully completed......................................
2026-02-08 21:59:54,080:INFO:Initializing plot_model()
2026-02-08 21:59:54,080:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 21:59:54,081:INFO:Checking exceptions
2026-02-08 21:59:54,083:INFO:Preloading libraries
2026-02-08 21:59:54,083:INFO:Copying training dataset
2026-02-08 21:59:54,083:INFO:Plot type: parameter
2026-02-08 21:59:54,086:INFO:Visual Rendered Successfully
2026-02-08 21:59:54,357:INFO:plot_model() successfully completed......................................
2026-02-08 21:59:56,397:INFO:Initializing plot_model()
2026-02-08 21:59:56,397:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 21:59:56,397:INFO:Checking exceptions
2026-02-08 21:59:56,400:INFO:Preloading libraries
2026-02-08 21:59:56,401:INFO:Copying training dataset
2026-02-08 21:59:56,401:INFO:Plot type: auc
2026-02-08 21:59:56,486:INFO:Fitting Model
2026-02-08 21:59:56,486:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2026-02-08 21:59:56,486:INFO:Scoring test/hold-out set
2026-02-08 21:59:56,824:INFO:Visual Rendered Successfully
2026-02-08 21:59:57,125:INFO:plot_model() successfully completed......................................
2026-02-08 21:59:58,691:INFO:Initializing plot_model()
2026-02-08 21:59:58,692:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 21:59:58,693:INFO:Checking exceptions
2026-02-08 21:59:58,698:INFO:Preloading libraries
2026-02-08 21:59:58,698:INFO:Copying training dataset
2026-02-08 21:59:58,698:INFO:Plot type: parameter
2026-02-08 21:59:58,708:INFO:Visual Rendered Successfully
2026-02-08 21:59:58,984:INFO:plot_model() successfully completed......................................
2026-02-08 22:00:00,009:INFO:Initializing plot_model()
2026-02-08 22:00:00,011:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 22:00:00,012:INFO:Checking exceptions
2026-02-08 22:00:00,021:INFO:Preloading libraries
2026-02-08 22:00:00,022:INFO:Copying training dataset
2026-02-08 22:00:00,023:INFO:Plot type: confusion_matrix
2026-02-08 22:00:00,142:INFO:Fitting Model
2026-02-08 22:00:00,142:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2026-02-08 22:00:00,143:INFO:Scoring test/hold-out set
2026-02-08 22:00:00,997:INFO:Visual Rendered Successfully
2026-02-08 22:00:01,299:INFO:plot_model() successfully completed......................................
2026-02-08 22:00:52,240:INFO:Initializing plot_model()
2026-02-08 22:00:52,240:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 22:00:52,240:INFO:Checking exceptions
2026-02-08 22:00:52,244:INFO:Preloading libraries
2026-02-08 22:00:52,245:INFO:Copying training dataset
2026-02-08 22:00:52,245:INFO:Plot type: pr
2026-02-08 22:00:52,307:INFO:Fitting Model
2026-02-08 22:00:52,358:INFO:Scoring test/hold-out set
2026-02-08 22:00:52,622:INFO:Visual Rendered Successfully
2026-02-08 22:00:52,906:INFO:plot_model() successfully completed......................................
2026-02-08 22:00:56,061:INFO:Initializing plot_model()
2026-02-08 22:00:56,061:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=vc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 22:00:56,061:INFO:Checking exceptions
2026-02-08 22:00:56,067:INFO:Preloading libraries
2026-02-08 22:00:56,067:INFO:Copying training dataset
2026-02-08 22:00:56,068:INFO:Plot type: vc
2026-02-08 22:00:56,069:INFO:Determining param_name
2026-02-08 22:00:56,070:INFO:param_name: var_smoothing
2026-02-08 22:00:56,198:INFO:Fitting Model
2026-02-08 22:00:59,963:INFO:Visual Rendered Successfully
2026-02-08 22:01:00,326:INFO:plot_model() successfully completed......................................
2026-02-08 22:01:00,338:INFO:Initializing plot_model()
2026-02-08 22:01:00,339:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=threshold, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 22:01:00,339:INFO:Checking exceptions
2026-02-08 22:01:03,431:INFO:Initializing plot_model()
2026-02-08 22:01:03,432:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7e79203a01d0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-08 22:01:03,432:INFO:Checking exceptions
2026-02-08 22:01:03,436:INFO:Preloading libraries
2026-02-08 22:01:03,436:INFO:Copying training dataset
2026-02-08 22:01:03,436:INFO:Plot type: confusion_matrix
2026-02-08 22:01:03,507:INFO:Fitting Model
2026-02-08 22:01:03,507:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2026-02-08 22:01:03,508:INFO:Scoring test/hold-out set
2026-02-08 22:01:04,360:INFO:Visual Rendered Successfully
2026-02-08 22:01:04,654:INFO:plot_model() successfully completed......................................
2026-02-09 14:57:35,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-09 14:57:35,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-09 14:57:35,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-09 14:57:35,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-09 14:59:27,270:INFO:PyCaret ClassificationExperiment
2026-02-09 14:59:27,271:INFO:Logging name: clf-default-name
2026-02-09 14:59:27,271:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-02-09 14:59:27,271:INFO:version 3.3.2
2026-02-09 14:59:27,271:INFO:Initializing setup()
2026-02-09 14:59:27,271:INFO:self.USI: 3f79
2026-02-09 14:59:27,271:INFO:self._variable_keys: {'X_test', 'y_test', 'fold_generator', 'html_param', 'USI', 'exp_name_log', 'fold_groups_param', 'logging_param', 'gpu_param', 'y_train', 'memory', 'X_train', '_ml_usecase', 'n_jobs_param', 'pipeline', 'target_param', 'X', 'is_multiclass', 'fix_imbalance', 'idx', 'log_plots_param', 'seed', '_available_plots', 'y', 'data', 'exp_id', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2026-02-09 14:59:27,271:INFO:Checking environment
2026-02-09 14:59:27,272:INFO:python_version: 3.11.14
2026-02-09 14:59:27,272:INFO:python_build: ('main', 'Nov 19 2025 22:47:14')
2026-02-09 14:59:27,272:INFO:machine: x86_64
2026-02-09 14:59:27,272:INFO:platform: Linux-6.14.0-37-generic-x86_64-with-glibc2.39
2026-02-09 14:59:27,273:INFO:Memory: svmem(total=8011505664, available=1371381760, percent=82.9, used=6640123904, free=519168000, active=3573030912, inactive=2776154112, buffers=40906752, cached=1808482304, shared=929988608, slab=495927296)
2026-02-09 14:59:27,275:INFO:Physical Core: 10
2026-02-09 14:59:27,275:INFO:Logical Core: 12
2026-02-09 14:59:27,275:INFO:Checking libraries
2026-02-09 14:59:27,275:INFO:System:
2026-02-09 14:59:27,275:INFO:    python: 3.11.14 (main, Nov 19 2025, 22:47:14) [Clang 21.1.4 ]
2026-02-09 14:59:27,275:INFO:executable: /home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/bin/python
2026-02-09 14:59:27,275:INFO:   machine: Linux-6.14.0-37-generic-x86_64-with-glibc2.39
2026-02-09 14:59:27,275:INFO:PyCaret required dependencies:
2026-02-09 14:59:27,278:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:27,367:INFO:                 pip: Not installed
2026-02-09 14:59:27,368:INFO:          setuptools: 81.0.0
2026-02-09 14:59:27,368:INFO:             pycaret: 3.3.2
2026-02-09 14:59:27,368:INFO:             IPython: 9.10.0
2026-02-09 14:59:27,368:INFO:          ipywidgets: 8.1.8
2026-02-09 14:59:27,368:INFO:                tqdm: 4.67.3
2026-02-09 14:59:27,368:INFO:               numpy: 1.26.4
2026-02-09 14:59:27,368:INFO:              pandas: 2.1.4
2026-02-09 14:59:27,368:INFO:              jinja2: 3.1.6
2026-02-09 14:59:27,368:INFO:               scipy: 1.11.4
2026-02-09 14:59:27,368:INFO:              joblib: 1.3.2
2026-02-09 14:59:27,368:INFO:             sklearn: 1.4.2
2026-02-09 14:59:27,368:INFO:                pyod: 2.0.6
2026-02-09 14:59:27,368:INFO:            imblearn: 0.14.1
2026-02-09 14:59:27,368:INFO:   category_encoders: 2.7.0
2026-02-09 14:59:27,368:INFO:            lightgbm: 4.6.0
2026-02-09 14:59:27,368:INFO:               numba: 0.63.1
2026-02-09 14:59:27,368:INFO:            requests: 2.32.5
2026-02-09 14:59:27,368:INFO:          matplotlib: 3.7.5
2026-02-09 14:59:27,368:INFO:          scikitplot: 0.3.7
2026-02-09 14:59:27,368:INFO:         yellowbrick: 1.5
2026-02-09 14:59:27,368:INFO:              plotly: 6.5.2
2026-02-09 14:59:27,368:INFO:    plotly-resampler: Not installed
2026-02-09 14:59:27,368:INFO:             kaleido: 1.2.0
2026-02-09 14:59:27,368:INFO:           schemdraw: 0.15
2026-02-09 14:59:27,368:INFO:         statsmodels: 0.14.6
2026-02-09 14:59:27,368:INFO:              sktime: 0.26.0
2026-02-09 14:59:27,368:INFO:               tbats: 1.1.3
2026-02-09 14:59:27,368:INFO:            pmdarima: 2.0.4
2026-02-09 14:59:27,368:INFO:              psutil: 7.2.2
2026-02-09 14:59:27,368:INFO:          markupsafe: 3.0.3
2026-02-09 14:59:27,368:INFO:             pickle5: Not installed
2026-02-09 14:59:27,369:INFO:         cloudpickle: 3.1.2
2026-02-09 14:59:27,369:INFO:         deprecation: 2.1.0
2026-02-09 14:59:27,369:INFO:              xxhash: 3.6.0
2026-02-09 14:59:27,369:INFO:           wurlitzer: 3.1.1
2026-02-09 14:59:27,369:INFO:PyCaret optional dependencies:
2026-02-09 14:59:27,425:INFO:                shap: Not installed
2026-02-09 14:59:27,425:INFO:           interpret: Not installed
2026-02-09 14:59:27,425:INFO:                umap: Not installed
2026-02-09 14:59:27,425:INFO:     ydata_profiling: Not installed
2026-02-09 14:59:27,425:INFO:  explainerdashboard: Not installed
2026-02-09 14:59:27,425:INFO:             autoviz: Not installed
2026-02-09 14:59:27,425:INFO:           fairlearn: Not installed
2026-02-09 14:59:27,425:INFO:          deepchecks: Not installed
2026-02-09 14:59:27,425:INFO:             xgboost: Not installed
2026-02-09 14:59:27,425:INFO:            catboost: Not installed
2026-02-09 14:59:27,426:INFO:              kmodes: Not installed
2026-02-09 14:59:27,426:INFO:             mlxtend: Not installed
2026-02-09 14:59:27,426:INFO:       statsforecast: Not installed
2026-02-09 14:59:27,426:INFO:        tune_sklearn: Not installed
2026-02-09 14:59:27,426:INFO:                 ray: Not installed
2026-02-09 14:59:27,426:INFO:            hyperopt: Not installed
2026-02-09 14:59:27,426:INFO:              optuna: Not installed
2026-02-09 14:59:27,426:INFO:               skopt: Not installed
2026-02-09 14:59:27,426:INFO:              mlflow: 3.9.0
2026-02-09 14:59:27,426:INFO:              gradio: Not installed
2026-02-09 14:59:27,426:INFO:             fastapi: 0.128.5
2026-02-09 14:59:27,426:INFO:             uvicorn: 0.40.0
2026-02-09 14:59:27,426:INFO:              m2cgen: Not installed
2026-02-09 14:59:27,426:INFO:           evidently: Not installed
2026-02-09 14:59:27,426:INFO:               fugue: Not installed
2026-02-09 14:59:27,426:INFO:           streamlit: Not installed
2026-02-09 14:59:27,426:INFO:             prophet: Not installed
2026-02-09 14:59:27,426:INFO:None
2026-02-09 14:59:27,426:INFO:Set up data.
2026-02-09 14:59:27,435:INFO:Set up folding strategy.
2026-02-09 14:59:27,435:INFO:Set up train/test split.
2026-02-09 14:59:27,442:INFO:Set up index.
2026-02-09 14:59:27,442:INFO:Assigning column types.
2026-02-09 14:59:27,449:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-09 14:59:27,512:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-09 14:59:27,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-09 14:59:27,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-09 14:59:27,586:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-09 14:59:27,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,610:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-09 14:59:27,650:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-09 14:59:27,674:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,714:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-09 14:59:27,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,738:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-02-09 14:59:27,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:27,874:INFO:Preparing preprocessing pipeline...
2026-02-09 14:59:27,876:INFO:Set up simple imputation.
2026-02-09 14:59:27,897:INFO:Finished creating preprocessing pipeline.
2026-02-09 14:59:27,902:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['N', 'P', 'K', 'temperature', 'ph',
                                             'humidity_log', 'rainfall_log'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2026-02-09 14:59:27,902:INFO:Creating final display dataframe.
2026-02-09 14:59:27,956:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type        Multiclass
3           Original data shape         (2200, 8)
4        Transformed data shape         (2200, 8)
5   Transformed train set shape         (1540, 8)
6    Transformed test set shape          (660, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3f79
2026-02-09 14:59:28,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:28,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:28,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:28,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-02-09 14:59:28,104:INFO:setup() successfully completed in 0.84s...............
2026-02-09 14:59:28,114:INFO:Initializing compare_models()
2026-02-09 14:59:28,115:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-02-09 14:59:28,115:INFO:Checking exceptions
2026-02-09 14:59:28,122:INFO:Preparing display monitor
2026-02-09 14:59:28,155:INFO:Initializing Logistic Regression
2026-02-09 14:59:28,156:INFO:Total runtime is 3.3934911092122394e-06 minutes
2026-02-09 14:59:28,160:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:28,161:INFO:Initializing create_model()
2026-02-09 14:59:28,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:28,161:INFO:Checking exceptions
2026-02-09 14:59:28,161:INFO:Importing libraries
2026-02-09 14:59:28,161:INFO:Copying training dataset
2026-02-09 14:59:28,169:INFO:Defining folds
2026-02-09 14:59:28,169:INFO:Declaring metric variables
2026-02-09 14:59:28,174:INFO:Importing untrained model
2026-02-09 14:59:28,180:INFO:Logistic Regression Imported successfully
2026-02-09 14:59:28,191:INFO:Starting cross validation
2026-02-09 14:59:28,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:31,905:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:31,905:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:31,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:31,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:31,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:31,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:31,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:31,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:31,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:31,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:32,236:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:32,240:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:32,256:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:32,256:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:32,259:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:32,259:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:32,264:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:32,268:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:32,269:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:32,271:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:32,309:INFO:Calculating mean and std
2026-02-09 14:59:32,319:INFO:Creating metrics dataframe
2026-02-09 14:59:32,339:INFO:Uploading results into container
2026-02-09 14:59:32,345:INFO:Uploading model into container now
2026-02-09 14:59:32,352:INFO:_master_model_container: 1
2026-02-09 14:59:32,363:INFO:_display_container: 2
2026-02-09 14:59:32,364:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-02-09 14:59:32,364:INFO:create_model() successfully completed......................................
2026-02-09 14:59:32,609:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:32,609:INFO:Creating metrics dataframe
2026-02-09 14:59:32,616:INFO:Initializing K Neighbors Classifier
2026-02-09 14:59:32,616:INFO:Total runtime is 0.07435059547424316 minutes
2026-02-09 14:59:32,620:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:32,620:INFO:Initializing create_model()
2026-02-09 14:59:32,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:32,620:INFO:Checking exceptions
2026-02-09 14:59:32,620:INFO:Importing libraries
2026-02-09 14:59:32,620:INFO:Copying training dataset
2026-02-09 14:59:32,625:INFO:Defining folds
2026-02-09 14:59:32,625:INFO:Declaring metric variables
2026-02-09 14:59:32,628:INFO:Importing untrained model
2026-02-09 14:59:32,632:INFO:K Neighbors Classifier Imported successfully
2026-02-09 14:59:32,637:INFO:Starting cross validation
2026-02-09 14:59:32,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:34,272:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:34,325:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2026-02-09 14:59:34,539:INFO:Calculating mean and std
2026-02-09 14:59:34,542:INFO:Creating metrics dataframe
2026-02-09 14:59:34,584:INFO:Uploading results into container
2026-02-09 14:59:34,589:INFO:Uploading model into container now
2026-02-09 14:59:34,594:INFO:_master_model_container: 2
2026-02-09 14:59:34,594:INFO:_display_container: 2
2026-02-09 14:59:34,598:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2026-02-09 14:59:34,598:INFO:create_model() successfully completed......................................
2026-02-09 14:59:35,452:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:35,452:INFO:Creating metrics dataframe
2026-02-09 14:59:35,461:INFO:Initializing Naive Bayes
2026-02-09 14:59:35,461:INFO:Total runtime is 0.12176395257314046 minutes
2026-02-09 14:59:35,465:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:35,465:INFO:Initializing create_model()
2026-02-09 14:59:35,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:35,465:INFO:Checking exceptions
2026-02-09 14:59:35,465:INFO:Importing libraries
2026-02-09 14:59:35,465:INFO:Copying training dataset
2026-02-09 14:59:35,473:INFO:Defining folds
2026-02-09 14:59:35,473:INFO:Declaring metric variables
2026-02-09 14:59:35,477:INFO:Importing untrained model
2026-02-09 14:59:35,483:INFO:Naive Bayes Imported successfully
2026-02-09 14:59:35,495:INFO:Starting cross validation
2026-02-09 14:59:35,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:35,662:INFO:Calculating mean and std
2026-02-09 14:59:35,664:INFO:Creating metrics dataframe
2026-02-09 14:59:35,665:INFO:Uploading results into container
2026-02-09 14:59:35,666:INFO:Uploading model into container now
2026-02-09 14:59:35,666:INFO:_master_model_container: 3
2026-02-09 14:59:35,666:INFO:_display_container: 2
2026-02-09 14:59:35,667:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-09 14:59:35,667:INFO:create_model() successfully completed......................................
2026-02-09 14:59:35,832:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:35,832:INFO:Creating metrics dataframe
2026-02-09 14:59:35,841:INFO:Initializing Decision Tree Classifier
2026-02-09 14:59:35,842:INFO:Total runtime is 0.1281051476796468 minutes
2026-02-09 14:59:35,846:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:35,846:INFO:Initializing create_model()
2026-02-09 14:59:35,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:35,846:INFO:Checking exceptions
2026-02-09 14:59:35,846:INFO:Importing libraries
2026-02-09 14:59:35,846:INFO:Copying training dataset
2026-02-09 14:59:35,852:INFO:Defining folds
2026-02-09 14:59:35,852:INFO:Declaring metric variables
2026-02-09 14:59:35,855:INFO:Importing untrained model
2026-02-09 14:59:35,858:INFO:Decision Tree Classifier Imported successfully
2026-02-09 14:59:35,866:INFO:Starting cross validation
2026-02-09 14:59:35,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:36,004:INFO:Calculating mean and std
2026-02-09 14:59:36,006:INFO:Creating metrics dataframe
2026-02-09 14:59:36,008:INFO:Uploading results into container
2026-02-09 14:59:36,009:INFO:Uploading model into container now
2026-02-09 14:59:36,011:INFO:_master_model_container: 4
2026-02-09 14:59:36,011:INFO:_display_container: 2
2026-02-09 14:59:36,011:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2026-02-09 14:59:36,011:INFO:create_model() successfully completed......................................
2026-02-09 14:59:36,157:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:36,157:INFO:Creating metrics dataframe
2026-02-09 14:59:36,165:INFO:Initializing SVM - Linear Kernel
2026-02-09 14:59:36,165:INFO:Total runtime is 0.13348976771036783 minutes
2026-02-09 14:59:36,168:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:36,168:INFO:Initializing create_model()
2026-02-09 14:59:36,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:36,168:INFO:Checking exceptions
2026-02-09 14:59:36,168:INFO:Importing libraries
2026-02-09 14:59:36,168:INFO:Copying training dataset
2026-02-09 14:59:36,172:INFO:Defining folds
2026-02-09 14:59:36,172:INFO:Declaring metric variables
2026-02-09 14:59:36,176:INFO:Importing untrained model
2026-02-09 14:59:36,179:INFO:SVM - Linear Kernel Imported successfully
2026-02-09 14:59:36,185:INFO:Starting cross validation
2026-02-09 14:59:36,186:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:36,280:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,288:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,288:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,291:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,293:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,303:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,305:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,312:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,314:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,318:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,339:INFO:Calculating mean and std
2026-02-09 14:59:36,340:INFO:Creating metrics dataframe
2026-02-09 14:59:36,344:INFO:Uploading results into container
2026-02-09 14:59:36,344:INFO:Uploading model into container now
2026-02-09 14:59:36,345:INFO:_master_model_container: 5
2026-02-09 14:59:36,346:INFO:_display_container: 2
2026-02-09 14:59:36,346:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2026-02-09 14:59:36,347:INFO:create_model() successfully completed......................................
2026-02-09 14:59:36,515:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:36,515:INFO:Creating metrics dataframe
2026-02-09 14:59:36,523:INFO:Initializing Ridge Classifier
2026-02-09 14:59:36,524:INFO:Total runtime is 0.1394707441329956 minutes
2026-02-09 14:59:36,526:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:36,527:INFO:Initializing create_model()
2026-02-09 14:59:36,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:36,527:INFO:Checking exceptions
2026-02-09 14:59:36,527:INFO:Importing libraries
2026-02-09 14:59:36,527:INFO:Copying training dataset
2026-02-09 14:59:36,533:INFO:Defining folds
2026-02-09 14:59:36,533:INFO:Declaring metric variables
2026-02-09 14:59:36,537:INFO:Importing untrained model
2026-02-09 14:59:36,542:INFO:Ridge Classifier Imported successfully
2026-02-09 14:59:36,550:INFO:Starting cross validation
2026-02-09 14:59:36,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:36,595:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,596:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,601:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,603:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:36,603:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:36,610:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,611:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,613:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:36,615:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,618:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,619:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,621:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:36,621:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,622:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:36,626:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:36,626:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:36,631:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:36,632:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:36,633:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:36,639:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:36,653:INFO:Calculating mean and std
2026-02-09 14:59:36,654:INFO:Creating metrics dataframe
2026-02-09 14:59:36,657:INFO:Uploading results into container
2026-02-09 14:59:36,658:INFO:Uploading model into container now
2026-02-09 14:59:36,659:INFO:_master_model_container: 6
2026-02-09 14:59:36,659:INFO:_display_container: 2
2026-02-09 14:59:36,660:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2026-02-09 14:59:36,660:INFO:create_model() successfully completed......................................
2026-02-09 14:59:36,820:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:36,820:INFO:Creating metrics dataframe
2026-02-09 14:59:36,828:INFO:Initializing Random Forest Classifier
2026-02-09 14:59:36,829:INFO:Total runtime is 0.14455560048421223 minutes
2026-02-09 14:59:36,832:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:36,832:INFO:Initializing create_model()
2026-02-09 14:59:36,832:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:36,832:INFO:Checking exceptions
2026-02-09 14:59:36,832:INFO:Importing libraries
2026-02-09 14:59:36,832:INFO:Copying training dataset
2026-02-09 14:59:36,836:INFO:Defining folds
2026-02-09 14:59:36,836:INFO:Declaring metric variables
2026-02-09 14:59:36,840:INFO:Importing untrained model
2026-02-09 14:59:36,843:INFO:Random Forest Classifier Imported successfully
2026-02-09 14:59:36,849:INFO:Starting cross validation
2026-02-09 14:59:36,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:37,590:INFO:Calculating mean and std
2026-02-09 14:59:37,592:INFO:Creating metrics dataframe
2026-02-09 14:59:37,594:INFO:Uploading results into container
2026-02-09 14:59:37,595:INFO:Uploading model into container now
2026-02-09 14:59:37,595:INFO:_master_model_container: 7
2026-02-09 14:59:37,596:INFO:_display_container: 2
2026-02-09 14:59:37,596:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2026-02-09 14:59:37,596:INFO:create_model() successfully completed......................................
2026-02-09 14:59:37,760:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:37,760:INFO:Creating metrics dataframe
2026-02-09 14:59:37,781:INFO:Initializing Quadratic Discriminant Analysis
2026-02-09 14:59:37,781:INFO:Total runtime is 0.16042524576187134 minutes
2026-02-09 14:59:37,789:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:37,790:INFO:Initializing create_model()
2026-02-09 14:59:37,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:37,791:INFO:Checking exceptions
2026-02-09 14:59:37,791:INFO:Importing libraries
2026-02-09 14:59:37,791:INFO:Copying training dataset
2026-02-09 14:59:37,803:INFO:Defining folds
2026-02-09 14:59:37,803:INFO:Declaring metric variables
2026-02-09 14:59:37,810:INFO:Importing untrained model
2026-02-09 14:59:37,817:INFO:Quadratic Discriminant Analysis Imported successfully
2026-02-09 14:59:37,827:INFO:Starting cross validation
2026-02-09 14:59:37,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:37,896:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:37,898:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:37,902:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:37,903:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:37,906:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:37,909:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:37,912:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:37,922:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:37,925:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:37,930:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:37,956:INFO:Calculating mean and std
2026-02-09 14:59:37,957:INFO:Creating metrics dataframe
2026-02-09 14:59:37,959:INFO:Uploading results into container
2026-02-09 14:59:37,960:INFO:Uploading model into container now
2026-02-09 14:59:37,960:INFO:_master_model_container: 8
2026-02-09 14:59:37,961:INFO:_display_container: 2
2026-02-09 14:59:37,961:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2026-02-09 14:59:37,961:INFO:create_model() successfully completed......................................
2026-02-09 14:59:38,120:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:38,120:INFO:Creating metrics dataframe
2026-02-09 14:59:38,137:INFO:Initializing Ada Boost Classifier
2026-02-09 14:59:38,137:INFO:Total runtime is 0.16636483271916708 minutes
2026-02-09 14:59:38,140:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:38,140:INFO:Initializing create_model()
2026-02-09 14:59:38,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:38,141:INFO:Checking exceptions
2026-02-09 14:59:38,141:INFO:Importing libraries
2026-02-09 14:59:38,141:INFO:Copying training dataset
2026-02-09 14:59:38,145:INFO:Defining folds
2026-02-09 14:59:38,145:INFO:Declaring metric variables
2026-02-09 14:59:38,149:INFO:Importing untrained model
2026-02-09 14:59:38,159:INFO:Ada Boost Classifier Imported successfully
2026-02-09 14:59:38,173:INFO:Starting cross validation
2026-02-09 14:59:38,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:38,226:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-09 14:59:38,234:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-09 14:59:38,238:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-09 14:59:38,239:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-09 14:59:38,244:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-09 14:59:38,253:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-09 14:59:38,254:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-09 14:59:38,257:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-09 14:59:38,275:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-09 14:59:38,276:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-09 14:59:38,497:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:38,502:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:38,508:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:38,512:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:38,541:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:38,547:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:38,549:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:38,549:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:38,549:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:38,552:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:38,552:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:38,554:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:38,556:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:38,556:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:38,559:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:38,559:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:38,565:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:38,571:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:38,615:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:38,619:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 14:59:38,628:INFO:Calculating mean and std
2026-02-09 14:59:38,630:INFO:Creating metrics dataframe
2026-02-09 14:59:38,633:INFO:Uploading results into container
2026-02-09 14:59:38,634:INFO:Uploading model into container now
2026-02-09 14:59:38,635:INFO:_master_model_container: 9
2026-02-09 14:59:38,635:INFO:_display_container: 2
2026-02-09 14:59:38,636:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2026-02-09 14:59:38,636:INFO:create_model() successfully completed......................................
2026-02-09 14:59:38,824:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:38,824:INFO:Creating metrics dataframe
2026-02-09 14:59:38,836:INFO:Initializing Gradient Boosting Classifier
2026-02-09 14:59:38,836:INFO:Total runtime is 0.17801862955093384 minutes
2026-02-09 14:59:38,840:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:38,841:INFO:Initializing create_model()
2026-02-09 14:59:38,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:38,841:INFO:Checking exceptions
2026-02-09 14:59:38,841:INFO:Importing libraries
2026-02-09 14:59:38,841:INFO:Copying training dataset
2026-02-09 14:59:38,848:INFO:Defining folds
2026-02-09 14:59:38,848:INFO:Declaring metric variables
2026-02-09 14:59:38,853:INFO:Importing untrained model
2026-02-09 14:59:38,858:INFO:Gradient Boosting Classifier Imported successfully
2026-02-09 14:59:38,866:INFO:Starting cross validation
2026-02-09 14:59:38,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:50,655:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:50,732:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:50,751:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:50,832:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:50,858:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:50,887:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:50,950:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:50,956:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:51,048:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:51,146:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:51,159:INFO:Calculating mean and std
2026-02-09 14:59:51,162:INFO:Creating metrics dataframe
2026-02-09 14:59:51,168:INFO:Uploading results into container
2026-02-09 14:59:51,169:INFO:Uploading model into container now
2026-02-09 14:59:51,171:INFO:_master_model_container: 10
2026-02-09 14:59:51,171:INFO:_display_container: 2
2026-02-09 14:59:51,173:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2026-02-09 14:59:51,174:INFO:create_model() successfully completed......................................
2026-02-09 14:59:51,920:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:51,920:INFO:Creating metrics dataframe
2026-02-09 14:59:51,930:INFO:Initializing Linear Discriminant Analysis
2026-02-09 14:59:51,930:INFO:Total runtime is 0.39624773263931273 minutes
2026-02-09 14:59:51,933:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:51,934:INFO:Initializing create_model()
2026-02-09 14:59:51,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:51,934:INFO:Checking exceptions
2026-02-09 14:59:51,934:INFO:Importing libraries
2026-02-09 14:59:51,934:INFO:Copying training dataset
2026-02-09 14:59:51,941:INFO:Defining folds
2026-02-09 14:59:51,941:INFO:Declaring metric variables
2026-02-09 14:59:51,947:INFO:Importing untrained model
2026-02-09 14:59:51,953:INFO:Linear Discriminant Analysis Imported successfully
2026-02-09 14:59:51,966:INFO:Starting cross validation
2026-02-09 14:59:51,967:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:52,052:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:52,057:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:52,061:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:52,062:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:52,066:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:52,082:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:52,082:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:52,084:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:52,084:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:52,092:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-09 14:59:52,126:INFO:Calculating mean and std
2026-02-09 14:59:52,129:INFO:Creating metrics dataframe
2026-02-09 14:59:52,132:INFO:Uploading results into container
2026-02-09 14:59:52,133:INFO:Uploading model into container now
2026-02-09 14:59:52,134:INFO:_master_model_container: 11
2026-02-09 14:59:52,134:INFO:_display_container: 2
2026-02-09 14:59:52,136:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2026-02-09 14:59:52,136:INFO:create_model() successfully completed......................................
2026-02-09 14:59:52,318:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:52,318:INFO:Creating metrics dataframe
2026-02-09 14:59:52,328:INFO:Initializing Extra Trees Classifier
2026-02-09 14:59:52,328:INFO:Total runtime is 0.4028733730316162 minutes
2026-02-09 14:59:52,331:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:52,331:INFO:Initializing create_model()
2026-02-09 14:59:52,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:52,331:INFO:Checking exceptions
2026-02-09 14:59:52,331:INFO:Importing libraries
2026-02-09 14:59:52,331:INFO:Copying training dataset
2026-02-09 14:59:52,336:INFO:Defining folds
2026-02-09 14:59:52,336:INFO:Declaring metric variables
2026-02-09 14:59:52,339:INFO:Importing untrained model
2026-02-09 14:59:52,342:INFO:Extra Trees Classifier Imported successfully
2026-02-09 14:59:52,350:INFO:Starting cross validation
2026-02-09 14:59:52,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 14:59:52,897:INFO:Calculating mean and std
2026-02-09 14:59:52,898:INFO:Creating metrics dataframe
2026-02-09 14:59:52,901:INFO:Uploading results into container
2026-02-09 14:59:52,901:INFO:Uploading model into container now
2026-02-09 14:59:52,902:INFO:_master_model_container: 12
2026-02-09 14:59:52,902:INFO:_display_container: 2
2026-02-09 14:59:52,903:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2026-02-09 14:59:52,903:INFO:create_model() successfully completed......................................
2026-02-09 14:59:53,073:INFO:SubProcess create_model() end ==================================
2026-02-09 14:59:53,073:INFO:Creating metrics dataframe
2026-02-09 14:59:53,084:INFO:Initializing Light Gradient Boosting Machine
2026-02-09 14:59:53,084:INFO:Total runtime is 0.4154791633288065 minutes
2026-02-09 14:59:53,088:INFO:SubProcess create_model() called ==================================
2026-02-09 14:59:53,089:INFO:Initializing create_model()
2026-02-09 14:59:53,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 14:59:53,089:INFO:Checking exceptions
2026-02-09 14:59:53,089:INFO:Importing libraries
2026-02-09 14:59:53,089:INFO:Copying training dataset
2026-02-09 14:59:53,093:INFO:Defining folds
2026-02-09 14:59:53,094:INFO:Declaring metric variables
2026-02-09 14:59:53,097:INFO:Importing untrained model
2026-02-09 14:59:53,100:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-09 14:59:53,106:INFO:Starting cross validation
2026-02-09 14:59:53,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 15:00:21,979:INFO:Calculating mean and std
2026-02-09 15:00:21,980:INFO:Creating metrics dataframe
2026-02-09 15:00:21,983:INFO:Uploading results into container
2026-02-09 15:00:21,983:INFO:Uploading model into container now
2026-02-09 15:00:21,984:INFO:_master_model_container: 13
2026-02-09 15:00:21,984:INFO:_display_container: 2
2026-02-09 15:00:21,985:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-02-09 15:00:21,985:INFO:create_model() successfully completed......................................
2026-02-09 15:00:22,153:INFO:SubProcess create_model() end ==================================
2026-02-09 15:00:22,154:INFO:Creating metrics dataframe
2026-02-09 15:00:22,164:INFO:Initializing Dummy Classifier
2026-02-09 15:00:22,164:INFO:Total runtime is 0.9001479268074035 minutes
2026-02-09 15:00:22,167:INFO:SubProcess create_model() called ==================================
2026-02-09 15:00:22,168:INFO:Initializing create_model()
2026-02-09 15:00:22,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758989f2dad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 15:00:22,168:INFO:Checking exceptions
2026-02-09 15:00:22,168:INFO:Importing libraries
2026-02-09 15:00:22,168:INFO:Copying training dataset
2026-02-09 15:00:22,172:INFO:Defining folds
2026-02-09 15:00:22,172:INFO:Declaring metric variables
2026-02-09 15:00:22,175:INFO:Importing untrained model
2026-02-09 15:00:22,178:INFO:Dummy Classifier Imported successfully
2026-02-09 15:00:22,184:INFO:Starting cross validation
2026-02-09 15:00:22,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 15:00:22,234:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 15:00:22,235:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 15:00:22,249:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 15:00:22,255:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 15:00:22,256:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 15:00:22,256:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 15:00:22,256:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 15:00:22,259:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 15:00:22,265:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 15:00:22,273:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-09 15:00:22,281:INFO:Calculating mean and std
2026-02-09 15:00:22,282:INFO:Creating metrics dataframe
2026-02-09 15:00:22,285:INFO:Uploading results into container
2026-02-09 15:00:22,286:INFO:Uploading model into container now
2026-02-09 15:00:22,287:INFO:_master_model_container: 14
2026-02-09 15:00:22,287:INFO:_display_container: 2
2026-02-09 15:00:22,287:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2026-02-09 15:00:22,287:INFO:create_model() successfully completed......................................
2026-02-09 15:00:22,485:INFO:SubProcess create_model() end ==================================
2026-02-09 15:00:22,485:INFO:Creating metrics dataframe
2026-02-09 15:00:22,503:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2026-02-09 15:00:22,513:INFO:Initializing create_model()
2026-02-09 15:00:22,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 15:00:22,514:INFO:Checking exceptions
2026-02-09 15:00:22,516:INFO:Importing libraries
2026-02-09 15:00:22,516:INFO:Copying training dataset
2026-02-09 15:00:22,521:INFO:Defining folds
2026-02-09 15:00:22,521:INFO:Declaring metric variables
2026-02-09 15:00:22,521:INFO:Importing untrained model
2026-02-09 15:00:22,521:INFO:Declaring custom model
2026-02-09 15:00:22,521:INFO:Naive Bayes Imported successfully
2026-02-09 15:00:22,522:INFO:Cross validation set to False
2026-02-09 15:00:22,522:INFO:Fitting Model
2026-02-09 15:00:22,537:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-09 15:00:22,537:INFO:create_model() successfully completed......................................
2026-02-09 15:00:22,732:INFO:_master_model_container: 14
2026-02-09 15:00:22,732:INFO:_display_container: 2
2026-02-09 15:00:22,732:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-09 15:00:22,732:INFO:compare_models() successfully completed......................................
2026-02-09 15:00:22,783:INFO:Initializing predict_model()
2026-02-09 15:00:22,783:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x758989d66340>)
2026-02-09 15:00:22,783:INFO:Checking exceptions
2026-02-09 15:00:22,783:INFO:Preloading libraries
2026-02-09 15:00:22,785:INFO:Set up data.
2026-02-09 15:00:22,798:INFO:Set up index.
2026-02-09 15:00:23,072:INFO:Initializing tune_model()
2026-02-09 15:00:23,073:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=50, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-02-09 15:00:23,073:INFO:Checking exceptions
2026-02-09 15:00:23,114:INFO:Copying training dataset
2026-02-09 15:00:23,123:INFO:Checking base model
2026-02-09 15:00:23,123:INFO:Base model : Naive Bayes
2026-02-09 15:00:23,134:INFO:Declaring metric variables
2026-02-09 15:00:23,142:INFO:Defining Hyperparameters
2026-02-09 15:00:23,142:INFO:50 is bigger than total combinations 28, setting search algorithm to grid
2026-02-09 15:00:23,343:INFO:Tuning with n_jobs=-1
2026-02-09 15:00:23,343:INFO:Initializing GridSearchCV
2026-02-09 15:00:24,082:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2026-02-09 15:00:24,083:INFO:Hyperparameter search completed
2026-02-09 15:00:24,083:INFO:SubProcess create_model() called ==================================
2026-02-09 15:00:24,083:INFO:Initializing create_model()
2026-02-09 15:00:24,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x758990ff2090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2026-02-09 15:00:24,083:INFO:Checking exceptions
2026-02-09 15:00:24,083:INFO:Importing libraries
2026-02-09 15:00:24,083:INFO:Copying training dataset
2026-02-09 15:00:24,087:INFO:Defining folds
2026-02-09 15:00:24,087:INFO:Declaring metric variables
2026-02-09 15:00:24,090:INFO:Importing untrained model
2026-02-09 15:00:24,090:INFO:Declaring custom model
2026-02-09 15:00:24,093:INFO:Naive Bayes Imported successfully
2026-02-09 15:00:24,100:INFO:Starting cross validation
2026-02-09 15:00:24,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 15:00:24,214:INFO:Calculating mean and std
2026-02-09 15:00:24,215:INFO:Creating metrics dataframe
2026-02-09 15:00:24,220:INFO:Finalizing model
2026-02-09 15:00:24,240:INFO:Uploading results into container
2026-02-09 15:00:24,241:INFO:Uploading model into container now
2026-02-09 15:00:24,242:INFO:_master_model_container: 15
2026-02-09 15:00:24,242:INFO:_display_container: 4
2026-02-09 15:00:24,242:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-09 15:00:24,242:INFO:create_model() successfully completed......................................
2026-02-09 15:00:24,417:INFO:SubProcess create_model() end ==================================
2026-02-09 15:00:24,418:INFO:choose_better activated
2026-02-09 15:00:24,422:INFO:SubProcess create_model() called ==================================
2026-02-09 15:00:24,423:INFO:Initializing create_model()
2026-02-09 15:00:24,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-09 15:00:24,423:INFO:Checking exceptions
2026-02-09 15:00:24,425:INFO:Importing libraries
2026-02-09 15:00:24,425:INFO:Copying training dataset
2026-02-09 15:00:24,432:INFO:Defining folds
2026-02-09 15:00:24,432:INFO:Declaring metric variables
2026-02-09 15:00:24,432:INFO:Importing untrained model
2026-02-09 15:00:24,432:INFO:Declaring custom model
2026-02-09 15:00:24,433:INFO:Naive Bayes Imported successfully
2026-02-09 15:00:24,433:INFO:Starting cross validation
2026-02-09 15:00:24,434:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-09 15:00:24,591:INFO:Calculating mean and std
2026-02-09 15:00:24,591:INFO:Creating metrics dataframe
2026-02-09 15:00:24,593:INFO:Finalizing model
2026-02-09 15:00:24,603:INFO:Uploading results into container
2026-02-09 15:00:24,604:INFO:Uploading model into container now
2026-02-09 15:00:24,604:INFO:_master_model_container: 16
2026-02-09 15:00:24,604:INFO:_display_container: 5
2026-02-09 15:00:24,604:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-09 15:00:24,604:INFO:create_model() successfully completed......................................
2026-02-09 15:00:24,766:INFO:SubProcess create_model() end ==================================
2026-02-09 15:00:24,767:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for F1 is 0.9948
2026-02-09 15:00:24,767:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for F1 is 0.9948
2026-02-09 15:00:24,767:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2026-02-09 15:00:24,767:INFO:choose_better completed
2026-02-09 15:00:24,767:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-02-09 15:00:24,777:INFO:_master_model_container: 16
2026-02-09 15:00:24,777:INFO:_display_container: 4
2026-02-09 15:00:24,777:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-09 15:00:24,777:INFO:tune_model() successfully completed......................................
2026-02-09 15:00:24,977:INFO:Initializing evaluate_model()
2026-02-09 15:00:24,978:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-02-09 15:00:24,992:INFO:Initializing plot_model()
2026-02-09 15:00:24,992:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-09 15:00:24,993:INFO:Checking exceptions
2026-02-09 15:00:24,997:INFO:Preloading libraries
2026-02-09 15:00:24,997:INFO:Copying training dataset
2026-02-09 15:00:24,997:INFO:Plot type: pipeline
2026-02-09 15:00:25,204:INFO:Visual Rendered Successfully
2026-02-09 15:00:25,363:INFO:plot_model() successfully completed......................................
2026-02-09 15:01:13,118:INFO:Initializing plot_model()
2026-02-09 15:01:13,119:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-09 15:01:13,119:INFO:Checking exceptions
2026-02-09 15:01:15,017:INFO:Initializing plot_model()
2026-02-09 15:01:15,017:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-09 15:01:15,017:INFO:Checking exceptions
2026-02-09 15:01:15,021:INFO:Preloading libraries
2026-02-09 15:01:15,022:INFO:Copying training dataset
2026-02-09 15:01:15,022:INFO:Plot type: pipeline
2026-02-09 15:01:15,108:INFO:Visual Rendered Successfully
2026-02-09 15:01:15,300:INFO:plot_model() successfully completed......................................
2026-02-09 15:01:47,609:INFO:Initializing plot_model()
2026-02-09 15:01:47,609:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7589900cfc10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-02-09 15:01:47,609:INFO:Checking exceptions
2026-02-09 15:01:47,614:INFO:Preloading libraries
2026-02-09 15:01:47,615:INFO:Copying training dataset
2026-02-09 15:01:47,615:INFO:Plot type: confusion_matrix
2026-02-09 15:01:47,686:INFO:Fitting Model
2026-02-09 15:01:47,687:WARNING:/home/lucas/Documents/Estudos/End-to-End Farm detection/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2026-02-09 15:01:47,687:INFO:Scoring test/hold-out set
2026-02-09 15:01:48,449:INFO:Visual Rendered Successfully
2026-02-09 15:01:48,694:INFO:plot_model() successfully completed......................................
